{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "#Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#ramdom generator\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "#CURL requests\n",
    "import requests \n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistics\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "# Strings\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('C:\\\\Users\\\\jnpicao\\\\Documents\\\\GitHub\\\\batch3-workspace\\\\Capstone\\\\data', 'train.csv')\n",
    "\n",
    "# Option for reading a sample of the file\n",
    "# sample 20% of the rows\n",
    "p = 1\n",
    "\n",
    "random.seed(178) # this is to get always the same sample. can be removed if we want the sample to change\n",
    "try:\n",
    "    df_original = pd.read_csv(file_path, \n",
    "                             skiprows = lambda row_num: random.random() > p and row_num > 0, \n",
    "                             #nrows = 10000, \n",
    "                             header=0,\n",
    "                             warn_bad_lines=True)\n",
    "except:\n",
    "    print('Ooops!!! We got an error!')\n",
    "else:\n",
    "    # Drop observations correspoding to stops that didn't lead to a search\n",
    "    df = df_original[df_original.VehicleSearchedIndicator==True].reset_index(drop=True).drop(columns='VehicleSearchedIndicator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='ContrabandIndicator'), \n",
    "                                                    df['ContrabandIndicator'], \n",
    "                                                    test_size=0.6, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classes for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom transformer to implement sentence cleaning\n",
    "# class TextCleanerTransformer(TransformerMixin):\n",
    "#     def __init__(self, \n",
    "#                  regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")], \n",
    "#                  lower=True, \n",
    "#                  remove_punct=True):\n",
    "#         self.regex_list = regex_list\n",
    "#         self.lower = lower\n",
    "#         self.remove_punct = remove_punct\n",
    "        \n",
    "#     def transform(self, X, *_):\n",
    "#         #X = list(map(self._clean_sentence, X.values))\n",
    "#         X_copy = X.copy()\n",
    "#         X_copy = X_copy.applymap(self._clean_sentence)\n",
    "#         return X_copy\n",
    "    \n",
    "#     def _clean_sentence(self, sentence):\n",
    "        \n",
    "#         # Make sure it is a string!\n",
    "#         sentence = str(sentence)\n",
    "        \n",
    "#         # Replace given regexes\n",
    "#         for regex in self.regex_list:\n",
    "#             sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "#         # lowercase\n",
    "#         if self.lower:\n",
    "#             sentence = sentence.lower()\n",
    "        \n",
    "#         # Trim\n",
    "#         sentence = sentence.strip()\n",
    "        \n",
    "#         return sentence\n",
    "    \n",
    "#     def fit(self, *_):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom transformer to implement sentence cleaning\n",
    "# class TextPreprocessor(TransformerMixin):\n",
    "#     def __init__(self, \n",
    "#                  regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")], \n",
    "#                  lower=True, \n",
    "#                  remove_punct=True):\n",
    "#         self.regex_list = regex_list\n",
    "#         self.lower = lower\n",
    "#         self.remove_punct = remove_punct\n",
    "        \n",
    "#     def transform(self, X, *_):\n",
    "#         X_copy = X.copy()\n",
    "#         X_copy = list(map(self._clean_sentence, X_copy))\n",
    "#         return X_copy\n",
    "    \n",
    "#     def _clean_sentence(self, sentence):\n",
    "        \n",
    "#         # Make sure it is a string!\n",
    "#         sentence = str(sentence)\n",
    "        \n",
    "#         # Replace given regexes\n",
    "#         for regex in self.regex_list:\n",
    "#             sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "#         # lowercase\n",
    "#         if self.lower:\n",
    "#             sentence = sentence.lower()\n",
    "        \n",
    "#         # Trim\n",
    "#         sentence = sentence.strip()\n",
    "        \n",
    "#         return sentence\n",
    "    \n",
    "#     def fit(self, *_):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self,\n",
    "#                  variety=\"BrE\",\n",
    "#                  user_abbrevs={},\n",
    "#                  n_jobs=1):\n",
    "#         \"\"\"\n",
    "#         Text preprocessing transformer includes steps:\n",
    "#             1. Text normalization\n",
    "#             2. Punctuation removal\n",
    "#             3. Stop words removal\n",
    "#             4. Lemmatization\n",
    "        \n",
    "#         variety - format of date (AmE - american type, BrE - british format) \n",
    "#         user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
    "#         n_jobs - parallel jobs to run\n",
    "#         \"\"\"\n",
    "#         self.variety = variety\n",
    "#         self.user_abbrevs = user_abbrevs\n",
    "#         self.n_jobs = n_jobs\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X, *_):\n",
    "#         X_copy = X.copy()\n",
    "\n",
    "#         partitions = 1\n",
    "#         cores = mp.cpu_count()\n",
    "#         if self.n_jobs <= -1:\n",
    "#             partitions = cores\n",
    "#         elif self.n_jobs <= 0:\n",
    "#             return X_copy.apply(self._preprocess_text)\n",
    "#         else:\n",
    "#             partitions = min(self.n_jobs, cores)\n",
    "\n",
    "#         data_split = np.array_split(X_copy, partitions)\n",
    "#         pool = mp.Pool(cores)\n",
    "#         data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "\n",
    "#         return data\n",
    "\n",
    "#     def _preprocess_part(self, part):\n",
    "#         return part.apply(self._preprocess_text)\n",
    "\n",
    "#     def _preprocess_text(self, text):\n",
    "#         normalized_text = self._normalize(text)\n",
    "#         doc = nlp(normalized_text)\n",
    "#         removed_punct = self._remove_punct(doc)\n",
    "#         removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "#         return self._lemmatize(removed_stop_words)\n",
    "\n",
    "#     def _normalize(self, text):\n",
    "#         # some issues in normalise package\n",
    "#         try:\n",
    "#             return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "#         except:\n",
    "#             return text\n",
    "\n",
    "#     def _remove_punct(self, doc):\n",
    "#         return [t for t in doc if t.text not in string.punctuation]\n",
    "\n",
    "#     def _remove_stop_words(self, doc):\n",
    "#         return [t for t in doc if not t.is_stop]\n",
    "\n",
    "#     def _lemmatize(self, doc):\n",
    "#         return ' '.join([t.lemma_ for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")], \n",
    "                 lower=True, \n",
    "                 remove_punct=True):\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        #X = list(map(self._clean_sentence, X.values))\n",
    "        X_copy = X.copy()\n",
    "        X_copy = X_copy.applymap(self._clean_sentence)\n",
    "        return X_copy\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Make sure it is a string!\n",
    "        sentence = str(sentence)\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "        \n",
    "        # Trim\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "    \n",
    "class BoolSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_pipe = Pipeline([\n",
    "#                 ('selector', TextSelector(['Department Name', 'SearchAuthorizationCode', 'StatuteReason'])),\n",
    "#                 ('cleaner', TextCleanerTransformer()),\n",
    "#                 ('ordinalencoder', ce.ordinal.OrdinalEncoder())\n",
    "#             ])\n",
    "\n",
    "text_pipe = Pipeline([\n",
    "                ('selector', TextSelector(['Department Name', 'SearchAuthorizationCode', 'StatuteReason'])),\n",
    "                ('ordinalencoder', ce.ordinal.OrdinalEncoder())\n",
    "            ])\n",
    "\n",
    "\n",
    "numerical_pipe =  Pipeline([\n",
    "                ('selector', NumberSelector(['SubjectAge'])),\n",
    "                ('binarizer', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform'))\n",
    "            ])\n",
    "\n",
    "# bool_pipe =  Pipeline([\n",
    "#                 ('selector', BoolSelector(['ResidentIndicator']))                \n",
    "#             ])\n",
    "\n",
    "# Feature Union allow use to use multiple distinct features in our classifier\n",
    "feats = FeatureUnion([('text', text_pipe), \n",
    "                      ('numerical', numerical_pipe)])\n",
    "\n",
    "#feats = FeatureUnion([('text', text_pipe)])\n",
    "\n",
    "# feats = FeatureUnion([('text', text_pipe), \n",
    "#                       ('numerical', numerical_pipe),\n",
    "#                       ('bool', bool_pipe)])\n",
    "\n",
    "pipe_clf = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jnpicao\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe_clf.fit(X_train, y_train)\n",
    "\n",
    "y_prob_pipe = pipe_clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "decision_thr = 0.5\n",
    "y_pred_pipe = y_prob_pipe > decision_thr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_pipe\n",
    "y_prob = y_prob_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5822126458132105"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5094266025224288"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7140033879164314"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pipeline = make_pipeline(TextCleanerTransformer(),\n",
    "#                          ce.ordinal.OrdinalEncoder(),\n",
    "#                          RandomForestClassifier(random_state = 42)\n",
    "#                          )\n",
    "# pipeline.fit(X_train[cols_to_use], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = pipeline.predict(X_test[cols_to_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['Department Name', 'SearchAuthorizationCode', 'StatuteReason', 'SubjectAge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns.json', 'w') as fh:\n",
    "    json.dump(X_train[cols_to_use].columns.tolist(), fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dtypes.pickle', 'wb') as fh:\n",
    "    pickle.dump(X_train[cols_to_use].dtypes, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pickle']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipe_clf, 'pipeline.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[-1,:].to_json('observation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deserialize and use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Department Name', 'SearchAuthorizationCode', 'StatuteReason', 'SubjectAge']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('columns.json', 'r') as fh:\n",
    "    cols = json.load(fh)\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department Name             object\n",
       "SearchAuthorizationCode     object\n",
       "StatuteReason               object\n",
       "SubjectAge                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('selector', TextSelector(key=['Department Name', 'SearchAuthorizationCode', 'StatuteReason'])), ('ordinalencoder', OrdinalEncoder(cols=['Department Name', 'SearchAuthorizationCode', 'St...mators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('pipeline.pickle', 'rb') as fh:\n",
    "    pipe_deserialized = joblib.load(fh)\n",
    "\n",
    "pipe_deserialized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('observation.json') as fh:\n",
    "    new_obs = json.load(fh)\n",
    "\n",
    "new_obs_str = json.dumps(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Department Name\": \"Darien\", \"InterventionDateTime\": \"08/28/2014 06:19:00 PM\", \"InterventionLocationName\": \"DARIEN\", \"InterventionReasonCode\": \"E\", \"ReportingOfficerIdentificationID\": \"PSC21368\", \"ResidentIndicator\": true, \"SearchAuthorizationCode\": \"I\", \"StatuteReason\": \"Defective Lights\", \"SubjectAge\": 27.0, \"SubjectEthnicityCode\": \"N\", \"SubjectRaceCode\": \"W\", \"SubjectSexCode\": \"M\", \"TownResidentIndicator\": false}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_obs_dict = json.loads(new_obs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department Name</th>\n",
       "      <th>SearchAuthorizationCode</th>\n",
       "      <th>StatuteReason</th>\n",
       "      <th>SubjectAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darien</td>\n",
       "      <td>I</td>\n",
       "      <td>Defective Lights</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Department Name SearchAuthorizationCode     StatuteReason  SubjectAge\n",
       "0          Darien                       I  Defective Lights        27.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame([new_obs_dict], columns=cols)\n",
    "obs = obs.astype(dtypes)\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use deserialized model to predict class of sample observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare result with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict_proba(obs)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9, 0.1]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_clf.predict_proba(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate observation samples for Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "del idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 2\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    idx = idx + 1\n",
    "except:\n",
    "    idx = 1\n",
    "\n",
    "print(\"i = {}\".format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48186"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed()\n",
    "row = random.choice(X_test.index.values)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New Haven', '02/05/2017 10:47:00 AM', 'NEW HAVEN', 'V', '6511',\n",
       "       True, 'O', 'Window Tint', 26.0, 'N', 'B', 'M', True], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[row,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict(X_test.loc[[row], cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89544387, 0.10455613]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict_proba(X_test.loc[[row], cols_to_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confirm result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89544387, 0.10455613]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_clf.predict_proba(X_test.loc[[row], cols_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\\\\"Department Name\\\\\":\\\\\"New Haven\\\\\",\\\\\"InterventionDateTime\\\\\":\\\\\"02\\\\/05\\\\/2017 10:47:00 AM\\\\\",\\\\\"InterventionLocationName\\\\\":\\\\\"NEW HAVEN\\\\\",\\\\\"InterventionReasonCode\\\\\":\\\\\"V\\\\\",\\\\\"ReportingOfficerIdentificationID\\\\\":\\\\\"6511\\\\\",\\\\\"ResidentIndicator\\\\\":true,\\\\\"SearchAuthorizationCode\\\\\":\\\\\"O\\\\\",\\\\\"StatuteReason\\\\\":\\\\\"Window Tint\\\\\",\\\\\"SubjectAge\\\\\":26.0,\\\\\"SubjectEthnicityCode\\\\\":\\\\\"N\\\\\",\\\\\"SubjectRaceCode\\\\\":\\\\\"B\\\\\",\\\\\"SubjectSexCode\\\\\":\\\\\"M\\\\\",\\\\\"TownResidentIndicator\\\\\":true}'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[row,:].to_json().replace('\"', '\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\\"id\\\": 2, \\\"observation\\\": {\\\"Department Name\\\":\\\"New Haven\\\",\\\"InterventionDateTime\\\":\\\"02\\/05\\/2017 10:47:00 AM\\\",\\\"InterventionLocationName\\\":\\\"NEW HAVEN\\\",\\\"InterventionReasonCode\\\":\\\"V\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"6511\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"O\\\",\\\"StatuteReason\\\":\\\"Window Tint\\\",\\\"SubjectAge\\\":26.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"B\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":true}}\n"
     ]
    }
   ],
   "source": [
    "new_request = '{\\\\\"id\\\\\": ' + str(idx) + ', \\\\\"observation\\\\\": ' +  + '}'\n",
    "print(new_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"{\\\"id\\\": 37, \\\"observation\\\": {\\\"Department Name\\\":\\\"State Police\\\",\\\"InterventionDateTime\\\":\\\"03\\/20\\/2015 12:49:00 PM\\\",\\\"InterventionLocationName\\\":\\\"WATERTOWN           \\\",\\\"InterventionReasonCode\\\":\\\"E\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"1000002596\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"O\\\",\\\"StatuteReason\\\":\\\"Other\\/Error\\\",\\\"SubjectAge\\\":20.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"W\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":false}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Department Name\":\"State Police\",\"InterventionDateTime\":\"03\\\\/20\\\\/2015 12:49:00 PM\",\"InterventionLocationName\":\"WATERTOWN           \",\"InterventionReasonCode\":\"E\",\"ReportingOfficerIdentificationID\":\"1000002596\",\"ResidentIndicator\":true,\"SearchAuthorizationCode\":\"O\",\"StatuteReason\":\"Other\\\\/Error\",\"SubjectAge\":20.0,\"SubjectEthnicityCode\":\"N\",\"SubjectRaceCode\":\"W\",\"SubjectSexCode\":\"M\",\"TownResidentIndicator\":false}'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[row,:].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-47ac47431dff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://heroku-app-model-deploy.herokuapp.com/predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m87\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"observation\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Department Name\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"State Police\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"InterventionDateTime\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"03\\\\/20\\\\/2015 12:49:00 PM\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"InterventionLocationName\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"WATERTOWN           \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"InterventionReasonCode\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"E\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ReportingOfficerIdentificationID\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"1000002596\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ResidentIndicator\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SearchAuthorizationCode\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"O\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"StatuteReason\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Other\\\\/Error\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SubjectAge\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SubjectEthnicityCode\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"N\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SubjectRaceCode\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SubjectSexCode\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"M\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"TownResidentIndicator\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "y = requests.post('https://heroku-app-model-deploy.herokuapp.com/predict', json = {\"id\": 87, \"observation\": {\"Department Name\":\"State Police\",\"InterventionDateTime\":\"03\\\\/20\\\\/2015 12:49:00 PM\",\"InterventionLocationName\":\"WATERTOWN           \",\"InterventionReasonCode\":\"E\",\"ReportingOfficerIdentificationID\":\"1000002596\",\"ResidentIndicator\":true,\"SearchAuthorizationCode\":\"O\",\"StatuteReason\":\"Other\\\\/Error\",\"SubjectAge\":20.0,\"SubjectEthnicityCode\":\"N\",\"SubjectRaceCode\":\"W\",\"SubjectSexCode\":\"M\",\"TownResidentIndicator\":false}})\n",
    "print(y.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-4d2859824441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://heroku-app-model-deploy.herokuapp.com/update'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"true_class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "y = requests.post('https://heroku-app-model-deploy.herokuapp.com/update', json = {\"id\": 3, \"true_class\": 1})\n",
    "print(y.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\\"id\\\": 16, \\\"observation\\\": {\\\"Department Name\\\":\\\"Vernon\\\",\\\"InterventionDateTime\\\":\\\"03\\/25\\/2018 11:16:00 PM\\\",\\\"InterventionLocationName\\\":\\\"VERNON\\\",\\\"InterventionReasonCode\\\":\\\"V\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"625\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"O\\\",\\\"StatuteReason\\\":\\\"Speed Related\\\",\\\"SubjectAge\\\":20.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"W\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":false}}\n"
     ]
    }
   ],
   "source": [
    "new_request = '{\\\\\"id\\\\\": 16, \\\\\"observation\\\\\": ' + X_test.loc[row,:].to_json().replace('\"', '\\\\\"') + '}'\n",
    "print(new_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.iloc[-1,:].to_json().replace('\"', '\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_request = '{\\\n",
    "\\\\\"id\\\\\": 0, \\\n",
    "\\\\\"observation\\\\\": {\\\\\"Department Name\\\\\":\\\\\"Bloomfield\\\\\",\\\\\"InterventionDateTime\\\\\":\\\\\"01\\\\/15\\\\/2018 05:01:00 PM\\\\\",\\\\\"InterventionLocationName\\\\\":\\\\\"Bloomfield\\\\\",\\\\\"InterventionReasonCode\\\\\":\\\\\"V\\\\\",\\\\\"ReportingOfficerIdentificationID\\\\\":\\\\\"2103\\\\\",\\\\\"ResidentIndicator\\\\\":true,\\\\\"SearchAuthorizationCode\\\\\":\\\\\"C\\\\\",\\\\\"StatuteReason\\\\\":\\\\\"Traffic Control Signal\\\\\",\\\\\"SubjectAge\\\\\":31.0,\\\\\"SubjectEthnicityCode\\\\\":\\\\\"N\\\\\",\\\\\"SubjectRaceCode\\\\\":\\\\\"B\\\\\",\\\\\"SubjectSexCode\\\\\":\\\\\"M\\\\\",\\\\\"TownResidentIndicator\\\\\":true}\\\n",
    "}'\n",
    "print(new_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"{\"Department Name\":\"Bloomfield\",\"InterventionDateTime\":\"01\\/15\\/2018 05:01:00 PM\",\"InterventionLocationName\":\"Bloomfield\",\"InterventionReasonCode\":\"V\",\"ReportingOfficerIdentificationID\":\"2103\",\"ResidentIndicator\":true,\"SearchAuthorizationCode\":\"C\",\"StatuteReason\":\"Traffic Control Signal\",\"SubjectAge\":31.0,\"SubjectEthnicityCode\":\"N\",\"SubjectRaceCode\":\"B\",\"SubjectSexCode\":\"M\",\"TownResidentIndicator\":true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"{\\\"id\\\": 0, \\\"observation\\\": {\\\"Department Name\\\":\\\"Bloomfield\\\",\\\"InterventionDateTime\\\":\\\"01\\/15\\/2018 05:01:00 PM\\\",\\\"InterventionLocationName\\\":\\\"Bloomfield\\\",\\\"InterventionReasonCode\\\":\\\"V\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"2103\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"C\\\",\\\"StatuteReason\\\":\\\"Traffic Control Signal\\\",\\\"SubjectAge\\\":31.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"B\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":true}}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
