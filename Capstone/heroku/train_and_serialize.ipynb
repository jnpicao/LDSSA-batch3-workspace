{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "#Pandas and Numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#ramdom generator\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "#Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Statistics\n",
    "from scipy.stats import binom_test\n",
    "\n",
    "# Strings\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean(doc, regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")] ):\n",
    "    \n",
    "    # Make sure it is a string!\n",
    "    doc = str(doc)\n",
    "    \n",
    "    # remove or replace characters\n",
    "    for regex in regex_list:\n",
    "        doc = re.sub(regex[0], regex[1], doc)\n",
    "    # lowercase\n",
    "    doc = doc.lower()\n",
    "    # Trim\n",
    "    doc = doc.strip()\n",
    "    # tokenize\n",
    "    #words = tokenizer.tokenize(doc)\n",
    "    # remove punctuation\n",
    "    #words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "    # stem\n",
    "    #stems = list(map(stemmer.stem, words))\n",
    "    #new_doc = \" \".join(stems)\n",
    "    new_doc = doc\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define class for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")], \n",
    "                 lower=True, \n",
    "                 remove_punct=True):\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        #X = list(map(self._clean_sentence, X.values))\n",
    "        X_copy = X.copy()\n",
    "        X_copy = X_copy.applymap(self._clean_sentence)\n",
    "        return X_copy\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Make sure it is a string!\n",
    "        sentence = str(sentence)\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "        \n",
    "        # Trim\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextPreprocessor(TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 regex_list=[(\"[\\.\\?\\(\\)\\|:;_!@/*\\-]\", \" \"), (\" +\", \" \")], \n",
    "                 lower=True, \n",
    "                 remove_punct=True):\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "        X_copy = list(map(self._clean_sentence, X_copy))\n",
    "        return X_copy\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Make sure it is a string!\n",
    "        sentence = str(sentence)\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "        \n",
    "        # Trim\n",
    "        sentence = sentence.strip()\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 variety=\"BrE\",\n",
    "                 user_abbrevs={},\n",
    "                 n_jobs=1):\n",
    "        \"\"\"\n",
    "        Text preprocessing transformer includes steps:\n",
    "            1. Text normalization\n",
    "            2. Punctuation removal\n",
    "            3. Stop words removal\n",
    "            4. Lemmatization\n",
    "        \n",
    "        variety - format of date (AmE - american type, BrE - british format) \n",
    "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
    "        n_jobs - parallel jobs to run\n",
    "        \"\"\"\n",
    "        self.variety = variety\n",
    "        self.user_abbrevs = user_abbrevs\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        partitions = 1\n",
    "        cores = mp.cpu_count()\n",
    "        if self.n_jobs <= -1:\n",
    "            partitions = cores\n",
    "        elif self.n_jobs <= 0:\n",
    "            return X_copy.apply(self._preprocess_text)\n",
    "        else:\n",
    "            partitions = min(self.n_jobs, cores)\n",
    "\n",
    "        data_split = np.array_split(X_copy, partitions)\n",
    "        pool = mp.Pool(cores)\n",
    "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _preprocess_part(self, part):\n",
    "        return part.apply(self._preprocess_text)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        normalized_text = self._normalize(text)\n",
    "        doc = nlp(normalized_text)\n",
    "        removed_punct = self._remove_punct(doc)\n",
    "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "        return self._lemmatize(removed_stop_words)\n",
    "\n",
    "    def _normalize(self, text):\n",
    "        # some issues in normalise package\n",
    "        try:\n",
    "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def _remove_punct(self, doc):\n",
    "        return [t for t in doc if t.text not in string.punctuation]\n",
    "\n",
    "    def _remove_stop_words(self, doc):\n",
    "        return [t for t in doc if not t.is_stop]\n",
    "\n",
    "    def _lemmatize(self, doc):\n",
    "        return ' '.join([t.lemma_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \".\\data\\train.csv\"\n",
    "#file_path = os.path.join('C:\\\\Users\\\\jnpicao\\\\Documents\\\\GitHub\\\\batch3-workspace\\\\Capstone', 'data', 'train.csv')\n",
    "file_path = os.path.join('C:\\\\Users\\\\jnpicao\\\\Documents\\\\GitHub', 'train.csv')\n",
    "\n",
    "# Option for reading a sample of the file\n",
    "# sample 20% of the rows\n",
    "p = 0.5\n",
    "\n",
    "random.seed(178) # this is to get always the same sample. can be removed if we want the sample to change\n",
    "try:\n",
    "    df_original = pd.read_csv(file_path, \n",
    "                             skiprows = lambda row_num: random.random() > p and row_num > 0, \n",
    "                             #nrows = 10000, \n",
    "                             header=0,\n",
    "                             warn_bad_lines=True)\n",
    "except:\n",
    "    print('Ooops!!! We got an error!')\n",
    "else:\n",
    "    # Drop observations correspoding to stops that didn't lead to a search\n",
    "    df = df_original[df_original.VehicleSearchedIndicator==True].reset_index(drop=True).drop(columns='VehicleSearchedIndicator')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='ContrabandIndicator'), \n",
    "                                                    df['ContrabandIndicator'], \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department Name</th>\n",
       "      <th>InterventionDateTime</th>\n",
       "      <th>InterventionLocationName</th>\n",
       "      <th>InterventionReasonCode</th>\n",
       "      <th>ReportingOfficerIdentificationID</th>\n",
       "      <th>ResidentIndicator</th>\n",
       "      <th>SearchAuthorizationCode</th>\n",
       "      <th>StatuteReason</th>\n",
       "      <th>SubjectAge</th>\n",
       "      <th>SubjectEthnicityCode</th>\n",
       "      <th>SubjectRaceCode</th>\n",
       "      <th>SubjectSexCode</th>\n",
       "      <th>TownResidentIndicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26546</th>\n",
       "      <td>Windsor</td>\n",
       "      <td>05/05/2017 05:33:00 AM</td>\n",
       "      <td>WINDSOR</td>\n",
       "      <td>V</td>\n",
       "      <td>205</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>Other</td>\n",
       "      <td>57.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>Farmington</td>\n",
       "      <td>05/09/2016 11:19:08 AM</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>V</td>\n",
       "      <td>390</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>24.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14762</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>12/28/2015 10:56:11 PM</td>\n",
       "      <td>GREENWICH</td>\n",
       "      <td>I</td>\n",
       "      <td>120000146</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Stop Sign</td>\n",
       "      <td>32.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6930</th>\n",
       "      <td>New Britain</td>\n",
       "      <td>07/21/2014 05:15:00 PM</td>\n",
       "      <td>New Britain</td>\n",
       "      <td>I</td>\n",
       "      <td>DCM0330</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>Suspended License</td>\n",
       "      <td>41.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>Norwich</td>\n",
       "      <td>10/25/2016 12:15:00 AM</td>\n",
       "      <td>NORWICH</td>\n",
       "      <td>V</td>\n",
       "      <td>1063</td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Department Name    InterventionDateTime InterventionLocationName  \\\n",
       "26546         Windsor  05/05/2017 05:33:00 AM                  WINDSOR   \n",
       "18116      Farmington  05/09/2016 11:19:08 AM               Farmington   \n",
       "14762       Greenwich  12/28/2015 10:56:11 PM                GREENWICH   \n",
       "6930      New Britain  07/21/2014 05:15:00 PM              New Britain   \n",
       "21620         Norwich  10/25/2016 12:15:00 AM                  NORWICH   \n",
       "\n",
       "      InterventionReasonCode ReportingOfficerIdentificationID  \\\n",
       "26546                      V                              205   \n",
       "18116                      V                              390   \n",
       "14762                      I                        120000146   \n",
       "6930                       I                          DCM0330   \n",
       "21620                      V                             1063   \n",
       "\n",
       "       ResidentIndicator SearchAuthorizationCode      StatuteReason  \\\n",
       "26546               True                       O              Other   \n",
       "18116               True                       O      Speed Related   \n",
       "14762              False                       C          Stop Sign   \n",
       "6930                True                       O  Suspended License   \n",
       "21620               True                       I   Moving Violation   \n",
       "\n",
       "       SubjectAge SubjectEthnicityCode SubjectRaceCode SubjectSexCode  \\\n",
       "26546        57.0                    N               W              M   \n",
       "18116        24.0                    H               W              M   \n",
       "14762        32.0                    H               W              M   \n",
       "6930         41.0                    H               W              M   \n",
       "21620        32.0                    N               W              F   \n",
       "\n",
       "       TownResidentIndicator  \n",
       "26546                  False  \n",
       "18116                   True  \n",
       "14762                  False  \n",
       "6930                    True  \n",
       "21620                  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19196 entries, 26546 to 15795\n",
      "Data columns (total 2 columns):\n",
      "Department Name    19196 non-null object\n",
      "StatuteReason      19195 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 449.9+ KB\n"
     ]
    }
   ],
   "source": [
    "cols_to_use = ['Department Name','StatuteReason']\n",
    "X_train[cols_to_use].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statutereason</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0  department name\n",
       "1    statutereason"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(map(simple_clean, X_train[cols_to_use])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'applymap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-554765b3c029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Department Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'applymap'"
     ]
    }
   ],
   "source": [
    "X_train['Department Name'].applymap(simple_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jnpicao\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('textcleanertransformer', <__main__.TextCleanerTransformer object at 0x000000768FCC60F0>), ('ordinalencoder', OrdinalEncoder(cols=['Department Name', 'StatuteReason'],\n",
       "        drop_invariant=False, handle_missing='value',\n",
       "        handle_unknown='value',\n",
       "        mapping=[{'col': 'Department N...mators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(TextCleanerTransformer(),\n",
    "                         ce.ordinal.OrdinalEncoder(),\n",
    "                         RandomForestClassifier(random_state = 42)\n",
    "                         )\n",
    "pipeline.fit(X_train[cols_to_use], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test[cols_to_use])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19196,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19196, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4989133059647428"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3322077504421933"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6755574077932903"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('columns.json', 'w') as fh:\n",
    "    json.dump(X_train[cols_to_use].columns.tolist(), fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dtypes.pickle', 'wb') as fh:\n",
    "    pickle.dump(X_train[cols_to_use].dtypes, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipeline.pickle']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, 'pipeline.pickle') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[-1,:].to_json('observation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deserialize and use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Department Name', 'StatuteReason']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('columns.json', 'r') as fh:\n",
    "    cols = json.load(fh)\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department Name    object\n",
       "StatuteReason      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('ordinalencoder', OrdinalEncoder(cols=[0, 1], drop_invariant=False, handle_missing='value',\n",
       "        handle_unknown='value',\n",
       "        mapping=[{'col': 0, 'mapping': Windsor             1\n",
       "Farmington          2\n",
       "Greenwich           3\n",
       "New Britain         4\n",
       "Norwich             5\n",
       "New Haven          ...mators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('pipeline.pickle', 'rb') as fh:\n",
    "    pipe_deserialized = joblib.load(fh)\n",
    "\n",
    "pipe_deserialized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('observation.json') as fh:\n",
    "    new_obs = json.load(fh)\n",
    "\n",
    "new_obs_str = json.dumps(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Department Name\": \"West Hartford\", \"InterventionDateTime\": \"02/08/2016 04:47:57 PM\", \"InterventionLocationName\": \"West Hartford\", \"InterventionReasonCode\": \"V\", \"ReportingOfficerIdentificationID\": \"1000002168\", \"ResidentIndicator\": true, \"SearchAuthorizationCode\": \"O\", \"StatuteReason\": \"Moving Violation\", \"SubjectAge\": 50.0, \"SubjectEthnicityCode\": \"N\", \"SubjectRaceCode\": \"W\", \"SubjectSexCode\": \"M\", \"TownResidentIndicator\": false}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_obs_dict = json.loads(new_obs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department Name</th>\n",
       "      <th>StatuteReason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Hartford</td>\n",
       "      <td>Moving Violation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Department Name     StatuteReason\n",
       "0   West Hartford  Moving Violation"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame([new_obs_dict], columns=cols)\n",
    "obs = obs.astype(dtypes)\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use deserialized model to predict class of sample observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict(obs.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare result with original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27238847, 0.72761153]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_deserialized.predict_proba(obs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27238847, 0.72761153]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(obs.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate observation samples for Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_sample():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35919"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed()\n",
    "row = random.choice(X_test.index.values)\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Vernon', '03/25/2018 11:16:00 PM', 'VERNON', 'V', '625', True,\n",
       "       'O', 'Speed Related', 20.0, 'N', 'W', 'M', False], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[row,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X_test.loc[[row],cols_to_use].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30813559, 0.69186441]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(X_test.loc[[row],cols_to_use].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\\\"id\\\": 16, \\\"observation\\\": {\\\"Department Name\\\":\\\"Vernon\\\",\\\"InterventionDateTime\\\":\\\"03\\/25\\/2018 11:16:00 PM\\\",\\\"InterventionLocationName\\\":\\\"VERNON\\\",\\\"InterventionReasonCode\\\":\\\"V\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"625\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"O\\\",\\\"StatuteReason\\\":\\\"Speed Related\\\",\\\"SubjectAge\\\":20.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"W\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":false}}\n"
     ]
    }
   ],
   "source": [
    "new_request = '{\\\\\"id\\\\\": 16, \\\\\"observation\\\\\": ' + X_test.loc[row,:].to_json().replace('\"', '\\\\\"') + '}'\n",
    "print(new_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.iloc[-1,:].to_json().replace('\"', '\\\\\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_request = '{\\\n",
    "\\\\\"id\\\\\": 0, \\\n",
    "\\\\\"observation\\\\\": {\\\\\"Department Name\\\\\":\\\\\"Bloomfield\\\\\",\\\\\"InterventionDateTime\\\\\":\\\\\"01\\\\/15\\\\/2018 05:01:00 PM\\\\\",\\\\\"InterventionLocationName\\\\\":\\\\\"Bloomfield\\\\\",\\\\\"InterventionReasonCode\\\\\":\\\\\"V\\\\\",\\\\\"ReportingOfficerIdentificationID\\\\\":\\\\\"2103\\\\\",\\\\\"ResidentIndicator\\\\\":true,\\\\\"SearchAuthorizationCode\\\\\":\\\\\"C\\\\\",\\\\\"StatuteReason\\\\\":\\\\\"Traffic Control Signal\\\\\",\\\\\"SubjectAge\\\\\":31.0,\\\\\"SubjectEthnicityCode\\\\\":\\\\\"N\\\\\",\\\\\"SubjectRaceCode\\\\\":\\\\\"B\\\\\",\\\\\"SubjectSexCode\\\\\":\\\\\"M\\\\\",\\\\\"TownResidentIndicator\\\\\":true}\\\n",
    "}'\n",
    "print(new_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"{\"Department Name\":\"Bloomfield\",\"InterventionDateTime\":\"01\\/15\\/2018 05:01:00 PM\",\"InterventionLocationName\":\"Bloomfield\",\"InterventionReasonCode\":\"V\",\"ReportingOfficerIdentificationID\":\"2103\",\"ResidentIndicator\":true,\"SearchAuthorizationCode\":\"C\",\"StatuteReason\":\"Traffic Control Signal\",\"SubjectAge\":31.0,\"SubjectEthnicityCode\":\"N\",\"SubjectRaceCode\":\"B\",\"SubjectSexCode\":\"M\",\"TownResidentIndicator\":true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(\"{\\\"id\\\": 0, \\\"observation\\\": {\\\"Department Name\\\":\\\"Bloomfield\\\",\\\"InterventionDateTime\\\":\\\"01\\/15\\/2018 05:01:00 PM\\\",\\\"InterventionLocationName\\\":\\\"Bloomfield\\\",\\\"InterventionReasonCode\\\":\\\"V\\\",\\\"ReportingOfficerIdentificationID\\\":\\\"2103\\\",\\\"ResidentIndicator\\\":true,\\\"SearchAuthorizationCode\\\":\\\"C\\\",\\\"StatuteReason\\\":\\\"Traffic Control Signal\\\",\\\"SubjectAge\\\":31.0,\\\"SubjectEthnicityCode\\\":\\\"N\\\",\\\"SubjectRaceCode\\\":\\\"B\\\",\\\"SubjectSexCode\\\":\\\"M\\\",\\\"TownResidentIndicator\\\":true}}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
