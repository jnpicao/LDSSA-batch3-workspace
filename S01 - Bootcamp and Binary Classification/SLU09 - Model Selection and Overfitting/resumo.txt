

Subtopics:
Offline evaluation
Leave-one-out or hold-out method
sklearn.model_selection.train_test_split
In-sample or training error
Out-of-sample or testing error
Validation dataset
Evaluating overfitting and underfitting
K-Fold cross-validation
sklearn.model_selection.cross_val_score
Data leakage
Practical considerations
Training time
Prediction time
Memory


The in-sample-error is how well our model performs on the training data.
We will measure the error rate for each model in the simplest way, by computing the fractions of misclassified cases.


Out-of-sample error (OSE) or testing error
The out-of-sample error measures how well the model performs on previsouly unseen data and if it's picking up patterns that generalize well.


There are different techniques to measure the testing error, we will focus on:

Train-test split
Validation set
Cross-validation
Bootstrapping




In k-fold cross validation:

The original sample is randomly partitioned into k equal sized parts, or subsamples

Each time, we leave out part k*, fit the model to the other *k-1 subsets combined in a single dataset, and then test the model against the left out kth part

This is done for each k* = 1, 2, ..., *K, and then the results are combined, using, for example, the mean error.





3. Regularized Linear Regression
Subtopics
Intuition and use-cases
Ridge, or L2
sklearn.linear_model.Ridge
Lasso, or L1
sklearn.linear_model.Lasso
Elastic Net
sklearn.linear_model.ElasticNet



from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)



from sklearn.metrics import accuracy_score

clf = LogisticRegression()
clf.fit(X_train, y_train)
y_pred = clf.predict(X)
error_rate = 1 - accuracy_score(y, y_pred)



from sklearn.model_selection import cross_val_score

scores = cross_val_score(clf, X, y, cv=10, scoring=classification_error)



from utils import expand_dataset, fit_and_plot_linear_regression

data = expand_dataset(original_data, 3)

fit_and_plot_linear_regression(data)




from sklearn.linear_model import Ridge

ridge = Ridge(normalize=True, alpha=0.0001, random_state=10)
ridge.fit(X, y)




from sklearn.linear_model import Lasso

lasso = Lasso(normalize=True, alpha=0.0002, random_state=10)
lasso.fit(X, y)




