{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b6b75485105e36c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BLU01 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26d8a5f531043e66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Important Note**\n",
    "\n",
    "When reading files, please use `os.path.join()`. Specially if you are a Windows user!\n",
    "The grader is running on Linux, reading a file my be running locally for you, but then don't run in the grader because of all the weird backslashes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0240afddd4fae69d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import hashlib # for grading purposes\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e0b4e1a40ebaaa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q1: Use a shell command to keep in 2 variables the first third and the last third of the lines existent in a file\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a3d2245d57305d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the file data/exercises/elon_musk.txt\n",
    "# Start by counting the total lines and add the total to the variable count_total.  \n",
    "# count_total = ...\n",
    "# YOUR CODE HERE\n",
    "#count_total = ! type .\\data\\exercises\\elon_musk.txt | find /c /v \"\"\n",
    "count_total = ! findstr /R /N \"^\" .\\data\\exercises\\elon_musk.txt | find /C \":\"\n",
    "count_total = int(count_total[0])\n",
    "count_total\n",
    "#count_total = 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e69c6137e73d90c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '4ec9599fc203d176a301536c2e091a19bc852759b255bd6818810a42c5fed14a'\n",
    "assert hashlib.sha256(str(count_total).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14cf2619322a8763",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# NOT GRADED optional exercise!!\n",
    "# Now add the first third and the last third of the lines to the variables first_third and last_third. \n",
    "# Make it work to any files using count_total/3 for instance in the bash commands\n",
    "# first_third = ...\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# last_third = ...\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6556340d1db98d7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Test the `first_third` and `last_third` exercise by running the following (ungraded) asserts.\n",
    "\n",
    "```\n",
    "assert first_third[-1][0] == 'H'\n",
    "assert last_third[0][0] == 'N'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e27cb8588bb5fd40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q2: Read a file with specific delimiter\n",
    "\n",
    "Read file **data/exercises/euribor_interest_rates.csv** into a pandas DataFrame.\n",
    "\n",
    "First, you should preview the file using a shell command in order to find out the used delimiter, and other properties of this file.\n",
    "\n",
    "Then, you should use function read_csv to read the data into a DataFrame. The resulting DataFrame should have the last column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-942e0590467e20d9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euribor 3 months|Euribor 6 months|Euribor 12 months|Years\n",
      "3,34|3,52|3,88|1999\n",
      "4,86|4,83|4,75|2000\n",
      "3,29|3,26|3,34|2001\n",
      "2,87|2,80|2,75|2002\n",
      "2,12|2,17|2,31|2003\n",
      "2,16|2,22|2,36|2004\n",
      "2,49|2,64|2,84|2005\n",
      "3,73|3,85|4,03|2006\n",
      "4,68|4,71|4,75|2007\n",
      "2,89|2,97|3,05|2008\n",
      "0,70|0,99|1,25|2009\n",
      "1,01|1,23|1,51|2010\n",
      "1,36|1,62|1,95|2011\n",
      "0,19|0,32|0,54|2012\n",
      "0,29|0,39|0,56|2013\n",
      "0,08|0,17|0,33|2014\n",
      "-0,13|-0,04|0,06|2015\n",
      "-0,32|-0,22|-0,08|2016\n",
      "-0,33|-0,27|-0,19|2017\n"
     ]
    }
   ],
   "source": [
    "# Use a shell command to preview the data\n",
    "# ! ...\n",
    "# YOUR CODE HERE\n",
    "! type .\\data\\exercises\\euribor_interest_rates.csv\n",
    "\n",
    "# Use function read_csv to read the data into a DataFrame\n",
    "# df2 = pd.read_csv(...)\n",
    "# YOUR CODE HERE\n",
    "df2 = pd.read_csv(os.path.join('data', 'exercises', 'euribor_interest_rates.csv'), sep = '|', index_col = -1, decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Euribor 3 months</th>\n",
       "      <th>Euribor 6 months</th>\n",
       "      <th>Euribor 12 months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>3.34</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>4.86</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>3.29</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.87</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2.12</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2.16</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>2.49</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>3.73</td>\n",
       "      <td>3.85</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>4.68</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2.89</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1.01</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>1.36</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Euribor 3 months  Euribor 6 months  Euribor 12 months\n",
       "Years                                                       \n",
       "1999               3.34              3.52               3.88\n",
       "2000               4.86              4.83               4.75\n",
       "2001               3.29              3.26               3.34\n",
       "2002               2.87              2.80               2.75\n",
       "2003               2.12              2.17               2.31\n",
       "2004               2.16              2.22               2.36\n",
       "2005               2.49              2.64               2.84\n",
       "2006               3.73              3.85               4.03\n",
       "2007               4.68              4.71               4.75\n",
       "2008               2.89              2.97               3.05\n",
       "2009               0.70              0.99               1.25\n",
       "2010               1.01              1.23               1.51\n",
       "2011               1.36              1.62               1.95\n",
       "2012               0.19              0.32               0.54\n",
       "2013               0.29              0.39               0.56\n",
       "2014               0.08              0.17               0.33\n",
       "2015              -0.13             -0.04               0.06\n",
       "2016              -0.32             -0.22              -0.08\n",
       "2017              -0.33             -0.27              -0.19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0c275c9acaa9c74d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df2.loc[2001, 'Euribor 3 months'] == 3.29\n",
    "assert set(df2.columns) == {'Euribor 3 months', 'Euribor 6 months', 'Euribor 12 months'}\n",
    "assert len(df2) == 19\n",
    "assert df2.index[0] == 1999\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df2.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6f9efef818e4a83",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q3: Read a csv file with problems\n",
    "\n",
    "Read file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. Pay attention to the following:\n",
    "* you might find some trouble when reading the file, at first, then just ignore the problems ;)\n",
    "* use the first column as index\n",
    "* there are some inputs in the file that should be interpreted as NaN, make sure you select the right one when reading the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2771b707556c08d2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years,Urban waste collection per inhabitant (kg/inhabitant),Selective urban waste collection per inhabitant (kg/inhabitant)\n",
      "1989,no-data,no-data\n",
      "1990,480,78.2,1990,,\n",
      "1991,425.7,1.5\n",
      "1992,999999,1.7\n",
      "1993,357.6,2.3\n",
      "1994,999999,999999\n",
      "1995,352.0,4.0\n",
      "1996,371.7,5.3\n",
      "1997,397.0,6.6\n",
      "1998,413.2,8.1\n",
      "1999,433.3,10.6\n",
      "2000,457.2,15.3\n",
      "2001,454.4,18.3\n",
      "2002,441.0,20.4\n",
      "2003,448.7,21.7\n",
      "2004,445.0,30.5\n",
      "2005,451.8,40.5\n",
      "2006,465.5,48.1\n",
      "2007,471.1,54.6\n",
      "2008,518.3,60.3\n",
      "2009,520.1,66.5\n",
      "2010,516.1,76.2\n",
      "2011,490.4,71.4\n",
      "2012,453.3,63.3\n",
      "2013,439.7,56.3\n",
      "2014,452.9,61.4\n",
      "2015,460.4,70.8\n",
      "2016,460.9,75.1\n",
      "2017,480,78.2,,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3: expected 3 fields, saw 6\\nSkipping line 30: expected 3 fields, saw 5\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv with read_csv\n",
    "# df3 = pd.read_csv(...)\n",
    "# YOUR CODE HERE\n",
    "! type .\\data\\exercises\\portugal_urban_waste_per_inhabitant.csv\n",
    "#df3 = pd.read_csv(os.path.join('data', 'exercises', 'portugal_urban_waste_per_inhabitant.csv'), usecols=[0,1,2], index_col=0, na_values=['no-data', '999999'])\n",
    "    \n",
    "df3 = pd.read_csv(os.path.join('data', 'exercises', 'portugal_urban_waste_per_inhabitant.csv'), \\\n",
    "                  error_bad_lines=False, index_col=0, na_values=['no-data', '999999'])\n",
    "#df3.iloc[1,0] = np.nan\n",
    "#df3.iloc[1,1] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "      <th>Selective urban waste collection per inhabitant (kg/inhabitant)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Years</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>425.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>357.6</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>352.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>371.7</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>397.0</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>413.2</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>433.3</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>457.2</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>454.4</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>441.0</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>448.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>445.0</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>451.8</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>465.5</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>471.1</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>518.3</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>520.1</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>516.1</td>\n",
       "      <td>76.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>490.4</td>\n",
       "      <td>71.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>453.3</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>439.7</td>\n",
       "      <td>56.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>452.9</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>460.4</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>460.9</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Urban waste collection per inhabitant (kg/inhabitant)  \\\n",
       "Years                                                          \n",
       "1989                                                 NaN       \n",
       "1991                                               425.7       \n",
       "1992                                                 NaN       \n",
       "1993                                               357.6       \n",
       "1994                                                 NaN       \n",
       "1995                                               352.0       \n",
       "1996                                               371.7       \n",
       "1997                                               397.0       \n",
       "1998                                               413.2       \n",
       "1999                                               433.3       \n",
       "2000                                               457.2       \n",
       "2001                                               454.4       \n",
       "2002                                               441.0       \n",
       "2003                                               448.7       \n",
       "2004                                               445.0       \n",
       "2005                                               451.8       \n",
       "2006                                               465.5       \n",
       "2007                                               471.1       \n",
       "2008                                               518.3       \n",
       "2009                                               520.1       \n",
       "2010                                               516.1       \n",
       "2011                                               490.4       \n",
       "2012                                               453.3       \n",
       "2013                                               439.7       \n",
       "2014                                               452.9       \n",
       "2015                                               460.4       \n",
       "2016                                               460.9       \n",
       "\n",
       "       Selective urban waste collection per inhabitant (kg/inhabitant)  \n",
       "Years                                                                   \n",
       "1989                                                 NaN                \n",
       "1991                                                 1.5                \n",
       "1992                                                 1.7                \n",
       "1993                                                 2.3                \n",
       "1994                                                 NaN                \n",
       "1995                                                 4.0                \n",
       "1996                                                 5.3                \n",
       "1997                                                 6.6                \n",
       "1998                                                 8.1                \n",
       "1999                                                10.6                \n",
       "2000                                                15.3                \n",
       "2001                                                18.3                \n",
       "2002                                                20.4                \n",
       "2003                                                21.7                \n",
       "2004                                                30.5                \n",
       "2005                                                40.5                \n",
       "2006                                                48.1                \n",
       "2007                                                54.6                \n",
       "2008                                                60.3                \n",
       "2009                                                66.5                \n",
       "2010                                                76.2                \n",
       "2011                                                71.4                \n",
       "2012                                                63.3                \n",
       "2013                                                56.3                \n",
       "2014                                                61.4                \n",
       "2015                                                70.8                \n",
       "2016                                                75.1                "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-601b354802964776",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df3.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df3.loc[2011, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 71.4\n",
    "\n",
    "mean_selective_waste = df3['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(35.632, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df3.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cfd5a97b1c49a0e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q4: Repair a csv file after importing\n",
    "Read the same file **data/exercises/portugal_urban_waste_per_inhabitant.csv** using function `read_csv`. But now, be sure you don't miss any lines with relevant information! \n",
    "\n",
    "* use csv module to import everything to a list of lists\n",
    "* create a df with only 3 meaningful columns, where the `Years` should be index\n",
    "* replace garbage values with NaN's \n",
    "* format the columns with the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-119041388e17fb72",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read file data/exercises/portugal_urban_waste_per_inhabitant.csv using  \n",
    "# lines = csv.reader(file)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# create a file object f\n",
    "f = open(os.path.join('data', 'exercises', 'portugal_urban_waste_per_inhabitant.csv'), 'r')\n",
    "\n",
    "# read the csv into a list of lists\n",
    "csv_list = list(csv.reader(f))\n",
    "\n",
    "num_cols = 3\n",
    "csv_list_clean = [i[0:num_cols] for i in csv_list]\n",
    "\n",
    "# create a dataframe using the line list with only 3 columns\n",
    "# df4 = pd.DataFrame(...\n",
    "# YOUR CODE HERE\n",
    "df4 = pd.DataFrame(csv_list_clean[1:], columns=csv_list_clean[0])\n",
    "\n",
    "#replace invalid values with nan (np.nan)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "#set types per dataframe column\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "#set a new index to the dataframe\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df4.Years = df4.Years.astype(int)\n",
    "df4 = df4.set_index('Years')\n",
    "\n",
    "df4 = df4.replace(['no-data', '999999'], np.nan)\n",
    "\n",
    "df4 = df4.astype(float)\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a42299f9047590d5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df4.loc[1994, 'Urban waste collection per inhabitant (kg/inhabitant)'])\n",
    "assert df4.loc[2012, 'Selective urban waste collection per inhabitant (kg/inhabitant)'] == 63.3\n",
    "\n",
    "mean_selective_waste = df4['Selective urban waste collection per inhabitant (kg/inhabitant)'].mean()\n",
    "assert math.isclose(38.78518518518518, mean_selective_waste, rel_tol=1e-3)\n",
    "\n",
    "expected_hash = 'b68ca0811f132f73edc68e9d3bebb288ef036c1fef8aabe6d2c63a2b6bfa859c'\n",
    "assert hashlib.sha256(df4.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-389bc42fe462c70e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5: Read a JSON file\n",
    "\n",
    "Read file **data/exercises/portugal_production_of_electricity_gwh.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c2125479f7e50e5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomass</th>\n",
       "      <th>Geothermal power</th>\n",
       "      <th>Hydropower &lt; 10MW</th>\n",
       "      <th>Hydropower &gt; 10MW</th>\n",
       "      <th>Photovoltaic</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total renewable sources</th>\n",
       "      <th>Windpower</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988</td>\n",
       "      <td>42</td>\n",
       "      <td>492</td>\n",
       "      <td>7962</td>\n",
       "      <td>1</td>\n",
       "      <td>33264</td>\n",
       "      <td>9501</td>\n",
       "      <td>16</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>959</td>\n",
       "      <td>49</td>\n",
       "      <td>658</td>\n",
       "      <td>14207</td>\n",
       "      <td>1</td>\n",
       "      <td>34520</td>\n",
       "      <td>15895</td>\n",
       "      <td>21</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1036</td>\n",
       "      <td>51</td>\n",
       "      <td>638</td>\n",
       "      <td>12537</td>\n",
       "      <td>1</td>\n",
       "      <td>34207</td>\n",
       "      <td>14301</td>\n",
       "      <td>38</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1022</td>\n",
       "      <td>58</td>\n",
       "      <td>566</td>\n",
       "      <td>12488</td>\n",
       "      <td>1</td>\n",
       "      <td>38984</td>\n",
       "      <td>14224</td>\n",
       "      <td>89</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081</td>\n",
       "      <td>80</td>\n",
       "      <td>589</td>\n",
       "      <td>7042</td>\n",
       "      <td>1</td>\n",
       "      <td>43287</td>\n",
       "      <td>8915</td>\n",
       "      <td>122</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Biomass  Geothermal power  Hydropower < 10MW  Hydropower > 10MW  \\\n",
       "0      988                42                492               7962   \n",
       "1      959                49                658              14207   \n",
       "2     1036                51                638              12537   \n",
       "3     1022                58                566              12488   \n",
       "4     1081                80                589               7042   \n",
       "\n",
       "   Photovoltaic  Total  Total renewable sources  Windpower  Year  \n",
       "0             1  33264                     9501         16  1995  \n",
       "1             1  34520                    15895         21  1996  \n",
       "2             1  34207                    14301         38  1997  \n",
       "3             1  38984                    14224         89  1998  \n",
       "4             1  43287                     8915        122  1999  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_production_of_electricity_gwh.json with read_json\n",
    "# df5 = read_json(...)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# create a file object f\n",
    "f = open(os.path.join('data', 'exercises', 'portugal_production_of_electricity_gwh.json'), 'r')\n",
    "\n",
    "#print(f.read())\n",
    "\n",
    "# closing the file\n",
    "f.close()\n",
    "\n",
    "df5 = pd.read_json(os.path.join('data', 'exercises', 'portugal_production_of_electricity_gwh.json'), orient='index')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f085fa2cdad9319",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df5) == 23\n",
    "assert set(df5.columns) == {'Biomass', 'Geothermal power', 'Hydropower < 10MW', 'Hydropower > 10MW', \n",
    "                           'Photovoltaic', 'Total','Total renewable sources','Windpower','Year'}\n",
    "\n",
    "expected_hash = 'c8226c54f1a24ae847c02a3e7a7d6e9fb44c2f82eb6f1fddcee9092c434e67fb'\n",
    "assert hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d4b970f55b3e427",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6: Read an Excel file\n",
    "\n",
    "Read file **data/exercises/portugal_gas_emissions_per_year.xlsx** using function read_excel. Pay attention to the following:\n",
    "\n",
    "* you should grab the table \"Series\" in sheet \"Metadata\"\n",
    "* use column 'Serie' as index\n",
    "* make sure you keep only the rows with data\n",
    "* set the variable distinct_scales with the number of ... distinct scales found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017a7c31b0ddc38e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_gas_emissions_per_year.xlsx with read_excel\n",
    "# df6 = read_excel(...)\n",
    "# YOUR CODE HERE\n",
    "df6 = pd.read_excel(os.path.join('data', 'exercises', 'portugal_gas_emissions_per_year.xlsx'),\n",
    "                    sheet_name='Metadata', skiprows=22, skipfooter=6, usecols=4, index_col=0)\n",
    "df6\n",
    "#distinct_scales = ...\n",
    "# YOUR CODE HERE\n",
    "distinct_scales = df6.Scale.nunique()\n",
    "distinct_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91d5f07e40585680",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert distinct_scales == 2\n",
    "assert isinstance(df6, pd.DataFrame)\n",
    "expected_hash = '60c3ad36f77e7366103fe36a3f551a0cde7d64e26d3102ddb8b953d6208a6006'\n",
    "assert hashlib.sha256(\n",
    "        df6.loc[\n",
    "            df6.index==\"Nitrogen oxides\", \n",
    "            \"Measure Unit\"][0].encode()\n",
    "    ).hexdigest() == expected_hash\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a7407517d4d92c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q7: Find the encoding of a file\n",
    "\n",
    "Find the encoding used in file **data/exercises/cities.csv**, using the method that was shown in the Learning Units.\n",
    "\n",
    "Then, read the data into a DataFrame, using the read_csv method and find the `City` characters that has distance equal to 7503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6944fd63bb38d8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the encoding of file data/exercises/mystery_cities.csv\n",
    "# encoding = ...\n",
    "# YOUR CODE HERE\n",
    "#f2 = os.path.join('data', 'exercises', 'cities.csv')\n",
    "#f2 = os.path.join('data', 'exercises', 'portugal_gas_emissions_per_year.xlsx')\n",
    "#print(f2)\n",
    "\n",
    "#chardet.detect(open(os.path.join('data', 'exercises', 'mystery_cities.csv'), 'rb').read())\n",
    "\n",
    "\n",
    "# Read the file into a DataFrame\n",
    "# df7 = ...\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# Find the name of the city with distance = 7503\n",
    "# distance_found = df7.loc[...]\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "\n",
    "import chardet\n",
    "#chardet.detect(open(os.path.join('data', 'exercises', 'cities.csv'), 'rb').read())\n",
    "encoding = chardet.detect(open(os.path.join('data', 'exercises', 'cities.csv'), 'rb').read())['encoding']\n",
    "\n",
    "df7 = pd.read_csv(os.path.join('data', 'exercises', 'cities.csv'), encoding=encoding)\n",
    "df7\n",
    "city_found = df7.City[3]\n",
    "\n",
    "#f = open(os.path.join('data', 'exercises', 'cities.csv'), 'rb')\n",
    "#print(f.read())\n",
    "\n",
    "#f = os.path.join('data', 'exercises', 'cities.csv')\n",
    "#print(f)\n",
    "#f\n",
    "#chardet.detect(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-687fb83c97e03355",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df7, pd.DataFrame)\n",
    "\n",
    "expected_hash_1 = '969aef39a1d4cb1c5928c774cd7a4e3ccfc064a18fbd43a70193a2631d8a122d'\n",
    "assert hashlib.sha256(encoding.encode()).hexdigest() == expected_hash_1\n",
    "\n",
    "expected_hash_2 = '8086d7adc029756c1b9094df64f6e79017dcc5a99c3c5e55b47beede11179a2b'\n",
    "assert hashlib.sha256(city_found.encode()).hexdigest() == expected_hash_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d103dfae3d5e11fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q8: Import a Random Sample of a Big File\n",
    "\n",
    "Consider the file **data/exercises/world_percentage_of_literacy.tsv**. Let's imagine this file is really huge, with a lot of rows!  Read the file using a random sample of 7 rows. Count the actual lines with `wc` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb39107093dd73fb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\exercises\\world_percentage_of_literacy.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Literacy rate (all)</th>\n",
       "      <th>Male literacy</th>\n",
       "      <th>Female literacy</th>\n",
       "      <th>Gender difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Israel</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>97.8% (2011)[4][note 5]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russia</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suriname</td>\n",
       "      <td>95.6%</td>\n",
       "      <td>96.1%</td>\n",
       "      <td>95.0%</td>\n",
       "      <td>1.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.8%</td>\n",
       "      <td>99.7%</td>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>86.5%</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>84.6%</td>\n",
       "      <td>4.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country          Literacy rate (all)            Male literacy  \\\n",
       "0    Denmark  not reported by UNESCO 2015                      NaN   \n",
       "1     Israel  not reported by UNESCO 2015  97.8% (2011)[4][note 5]   \n",
       "2  Lithuania                        99.8%                    99.8%   \n",
       "3     Russia                        99.7%                    99.7%   \n",
       "4   Suriname                        95.6%                    96.1%   \n",
       "5    Ukraine                        99.8%                    99.8%   \n",
       "6   Zimbabwe                        86.5%                    88.5%   \n",
       "\n",
       "  Female literacy Gender difference  \n",
       "0             NaN               NaN  \n",
       "1             NaN               NaN  \n",
       "2           99.8%              0.0%  \n",
       "3           99.7%              0.0%  \n",
       "4           95.0%              1.1%  \n",
       "5           99.7%              0.1%  \n",
       "6           84.6%              4.0%  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv with wc and save the number of lines\n",
    "# in lines_in_file. Notice that the header is not a line..\n",
    "# don't forget to close the opened file\n",
    "# YOUR CODE HERE\n",
    "import random\n",
    "\n",
    "file = os.path.join(\"data\", \"exercises\", \"world_percentage_of_literacy.tsv\")\n",
    "print(file)\n",
    "\n",
    "# 1-Find number of rows\n",
    "#n_total_rows = ! findstr /R /N \"^\" \".\\data\\pokemons\\pokemons.csv\" | find /C \":\"\n",
    "lines_in_file = ! findstr /R /N \"^\" \".\\data\\exercises\\world_percentage_of_literacy.tsv\" | find /C \":\"\n",
    "lines_in_file = int(lines_in_file[0]) - 1\n",
    "lines_in_file\n",
    "\n",
    "\n",
    "# make parameter rows_to_skip equal to the lines you want to skip loading \n",
    "# don't forget: \n",
    "# - 7 rows should be fecthed)\n",
    "# - you want to keep the header plus 7 rows in the new dataframe...\n",
    "# rows_to_skip = ...\n",
    "# YOUR CODE HERE\n",
    "n_rows_to_read = 7\n",
    "n_rows_to_skip = lines_in_file - n_rows_to_read\n",
    "\n",
    "#random.seed(42) # this is to get always the same sample. can be removed if we want the sample to change\n",
    "rows_to_skip = random.sample(\n",
    "    range(1, lines_in_file), # this is a range from the first row after the header, to the last row on the file\n",
    "    n_rows_to_skip # this is the number of rows we want to sample, i.e, to skip\n",
    ")\n",
    "\n",
    "# Create a df8 file with the sampled values\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df8 = pd.read_csv( file, sep = '\\t', skiprows=rows_to_skip)\n",
    "df8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec15a8be42137a01",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# getting remaining list of countries, removing rows_to_skip from the file\n",
    "df_helper = pd.read_csv( \n",
    "    'data/exercises/world_percentage_of_literacy.tsv', \n",
    "    sep='\\t',\n",
    "    header=0 \n",
    ")\n",
    "\n",
    "total_indexes = list(df_helper.index)\n",
    "for s in rows_to_skip:\n",
    "    total_indexes.remove(s-1)\n",
    "\n",
    "assert lines_in_file==194\n",
    "assert isinstance(df8, pd.DataFrame)\n",
    "assert list(df8['Country'])==list(df_helper.iloc[total_indexes]['Country'])\n",
    "assert df8.shape[0]==7\n",
    "\n",
    "expected_hash = '7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451'\n",
    "assert  hashlib.sha256(str(df8.shape[0]).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e07a7b2cacd9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q9: Loading a Big File\n",
    "\n",
    "Read file **data/exercises/world_percentage_of_literacy.tsv** using chunks keep only the columns `Country` and `Literacy rate (all)`.\n",
    "Note that:\n",
    "* file should be read by chunks of 10 countries\n",
    "* the missing values should be removed (filtered in each chunk)\n",
    "* the `Literacy rate (all)` should be converted to type float (in each chunk)\n",
    "* the index should be incremental starting from 0 (i.e, you don't need to read any column as the index)\n",
    "\n",
    "In the end calculate the average `Literacy rate (all)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5106c25a705296e8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12569.8\n",
      "151\n",
      "83.24370860927151\n",
      "83.24370860927152\n",
      "83.24370860927152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Literacy rate (all)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83.243709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.986731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Literacy rate (all)\n",
       "count           151.000000\n",
       "mean             83.243709\n",
       "std              18.986731\n",
       "min              19.100000\n",
       "25%              74.400000\n",
       "50%              91.800000\n",
       "75%              98.000000\n",
       "max             100.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the chunks should be appended in a list called chunk_arr\n",
    "# YOUR CODE HERE\n",
    "file = os.path.join(\"data\", \"exercises\", \"world_percentage_of_literacy.tsv\")\n",
    "chunks_iter = pd.read_csv( file, sep = '\\t',  chunksize = 10, na_values=['not reported by UNESCO 2015'])\n",
    "\n",
    "chunk_arr = []\n",
    "for chunk_data in chunks_iter:\n",
    "    chunk_data_cln = chunk_data[['Country', 'Literacy rate (all)']]\n",
    "    chunk_data_cln = chunk_data_cln.dropna()\n",
    "    chunk_data_cln['Literacy rate (all)'] = chunk_data_cln['Literacy rate (all)'].str.split(pat='%', expand=True)[0]\n",
    "    chunk_data_cln['Literacy rate (all)'] = chunk_data_cln['Literacy rate (all)'].astype(float)\n",
    "    #print(chunk_data_cln)\n",
    "    chunk_arr.append(chunk_data_cln)\n",
    "\n",
    "\n",
    "# df9 should be the final dataframe with concatenated chunks\n",
    "# Resulting average should go on lit_avg variable\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df9 = pd.concat(chunk_arr, axis=0, ignore_index=True)\n",
    "\n",
    "lit_avg = df9['Literacy rate (all)'].mean()\n",
    "lit_avg = df9['Literacy rate (all)'].sum()/df9['Literacy rate (all)'].size\n",
    "\n",
    "#print(df9.head(10))\n",
    "#df9.info()\n",
    "print(df9['Literacy rate (all)'].sum())\n",
    "print(df9['Literacy rate (all)'].size)\n",
    "print(df9['Literacy rate (all)'].mean())\n",
    "print(df9['Literacy rate (all)'].sum()/df9['Literacy rate (all)'].size)\n",
    "print(12569.8/151)\n",
    "df9.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f60a22c3465d5b83",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df9.loc[df9['Country']=='World', 'Literacy rate (all)'].values[0] == 86.3\n",
    "assert df9.dtypes['Country'] == np.object\n",
    "assert df9.dtypes['Literacy rate (all)'] == np.float\n",
    "\n",
    "expected_hash = 'f26cd8ca964afd7aaaea0cacb142419676cf9928772f5b5310a036ffdae1586a'\n",
    "assert hashlib.sha256(str([len(c) for c in chunk_arr]).encode()).hexdigest() == expected_hash\n",
    "\n",
    "expected_hash = '94f2bba3a658b5642ebbc9b952af45c3db1a185ae0357e4fe7ced784f0c3fe29'\n",
    "assert hashlib.sha256(str(lit_avg).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e990312f7cddd0b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q10: Calculate average values using chunks and avoiding a complete data frame in memory.\n",
    "\n",
    "Using chunks, read file **data/exercises/world_percentage_of_literacy.tsv**, avoid incompleted rows and calculate the average of ***Literacy rate (all)*** without loading all data simultaneously. Use a similar approach of the previous question but don't create any dataframe neither any list with chunks;\n",
    "\n",
    "***Hint: Use the average definition***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fd7700885246eb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "12569.8\n",
      "83.24370860927154\n"
     ]
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "# the final average should be in the variable final_avg\n",
    "# You should increment 2 variables in each chunk and use them at the end to calculate final_avg. call them lit_a, lit_b\n",
    "# YOUR CODE HERE\n",
    "\n",
    "file = os.path.join(\"data\", \"exercises\", \"world_percentage_of_literacy.tsv\")\n",
    "chunks_iter = pd.read_csv( file, sep = '\\t',  chunksize = 10, na_values=['not reported by UNESCO 2015'])\n",
    "\n",
    "lit_a = 0\n",
    "lit_b = 0\n",
    "for chunk_data in chunks_iter:\n",
    "    chunk_data_cln = chunk_data[['Country', 'Literacy rate (all)']]\n",
    "    chunk_data_cln = chunk_data_cln.dropna()\n",
    "    chunk_data_cln['Literacy rate (all)'] = chunk_data_cln['Literacy rate (all)'].str.split(pat='%', expand=True)[0]\n",
    "    chunk_data_cln['Literacy rate (all)'] = chunk_data_cln['Literacy rate (all)'].astype(float)\n",
    "    \n",
    "    lit_a += chunk_data_cln.shape[0]\n",
    "    lit_b += chunk_data_cln['Literacy rate (all)'].sum()\n",
    "    \n",
    "print(lit_a)\n",
    "print(round(lit_b,3))\n",
    "\n",
    "final_avg = lit_b/lit_a\n",
    "print(final_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0edcf1260d7886c9",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(83.24370860927154, final_avg, rel_tol=1e-1)\n",
    "assert lit_b==151 or lit_a==151\n",
    "assert int(lit_b) == 12569 or int(lit_a)==12569"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
