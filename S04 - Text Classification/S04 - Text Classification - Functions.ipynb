{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Receive all documents (i.e. texts) as a `List`, `DataFrame` or `Series`.  \n",
    "\n",
    "\n",
    "* Define function to clean a string:\n",
    " * ```python\n",
    "     def clean(doc, regex_list=[(\"<[^>]*>\", \"\")] ):\n",
    "        \n",
    "        # remove or replace characters\n",
    "        for regex in regex_list:\n",
    "            doc = re.sub(regex[0], regex[1], doc)\n",
    "        # lowercase\n",
    "        doc = doc.lower()\n",
    "        # tokenize\n",
    "        words = tokenizer.tokenize(doc)\n",
    "        # remove punctuation\n",
    "        words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "        # stem\n",
    "        stems = list(map(stemmer.stem, words))\n",
    "        new_doc = \" \".join(stems)\n",
    "        return new_doc\n",
    "   ```  \n",
    "\n",
    "\n",
    "* Appy `df.applymap(clean)` or `series.apply(clean)` or List comprehension.   \n",
    "\n",
    "\n",
    "* Define a function to build the set of distinct words (i.e., the vocabulary) occurring in `docs` (see `Counter()` and `OrderedDict()` in [library collections](https://docs.python.org/2/library/collections.html)):\n",
    " * ```python\n",
    "     def build_vocabulary(docs):\n",
    "        vocabulary = Counter()\n",
    "\n",
    "        for doc in docs:\n",
    "            words = doc.split()\n",
    "            vocabulary.update(words)\n",
    "\n",
    "        return OrderedDict(vocabulary.most_common())\n",
    " ```\n",
    "\n",
    "\n",
    "* Define a function to vectorize the documents, i.e., convert documents into a table where each line represents one document and the columns are the word counts.  \n",
    " * ```python\n",
    "     def vectorize(docs):\n",
    "        vocabulary = build_vocabulary()\n",
    "        vectors = []\n",
    "        for doc in docs:\n",
    "            vector = np.array([doc.count(word) for word in vocabulary])\n",
    "            vectors.append(vector)\n",
    "\n",
    "        return vectors\n",
    " ```\n",
    "\n",
    "* `docs_BOW = pd.DataFrame(vectorize(), columns=build_vocabulary())`  \n",
    "\n",
    "\n",
    "* Improvements to the bag of words representation:\n",
    " * Remove *stop words*\n",
    " * Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    " * nest\n",
    "\n",
    "**Or...**\n",
    "\n",
    "* use fsadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of a `clean()` function define a sklearn `Class` with the clean function inside so we can call a `transform()` method to apply the cleaning to each document. In this way we can include this step in a Pipeline.  \n",
    "\n",
    "\n",
    "* Use sklearn [CountVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) instead of `build_vocabulary()` + `vectorize()`.  \n",
    "It receives an iterable of documents and returns a vectorized sparse matrix of token counts of those documents.  \n",
    "\n",
    "\n",
    "* Use sklearn [TfidfTransformer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html) to transform a count matrix to a normalized tf or tf-idf representation.  \n",
    "`CountVectorizer()` followed by `TfidfTransformer()` is equivalent to [TfidfVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).  \n",
    "\n",
    "\n",
    "* next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Aldolpho (Steve Buscemi), an aspiring film mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>An unfunny, unworthy picture which is an undes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>A failure. The movie was just not good. It has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I saw this movie Sunday afternoon. I absolutel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Disney goes to the well one too many times as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Negative  Aldolpho (Steve Buscemi), an aspiring film mak...\n",
       "1  Negative  An unfunny, unworthy picture which is an undes...\n",
       "2  Negative  A failure. The movie was just not good. It has...\n",
       "3  Positive  I saw this movie Sunday afternoon. I absolutel...\n",
       "4  Negative  Disney goes to the well one too many times as ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./BLU07 - Feature Extraction/data/imdb_sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    5000 non-null object\n",
      "text         5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
