{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Receive all documents (i.e. texts) as a `List`, `DataFrame` or `Series`.  \n",
    "\n",
    "\n",
    "* Define function to clean a string:\n",
    " * ```python\n",
    "     def clean(doc, regex_list=[(\"<[^>]*>\", \"\")] ):\n",
    "        \n",
    "        # remove or replace characters\n",
    "        for regex in regex_list:\n",
    "            doc = re.sub(regex[0], regex[1], doc)\n",
    "        # lowercase\n",
    "        doc = doc.lower()\n",
    "        # tokenize\n",
    "        words = tokenizer.tokenize(doc)\n",
    "        # remove punctuation\n",
    "        words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "        # stem\n",
    "        stems = list(map(stemmer.stem, words))\n",
    "        new_doc = \" \".join(stems)\n",
    "        return new_doc\n",
    "   ```  \n",
    "\n",
    "\n",
    "* Appy `df.applymap(clean)` or `series.apply(clean)` or List comprehension.   \n",
    "\n",
    "\n",
    "* Define a function to build the set of distinct words (i.e., the vocabulary) occurring in `docs` (see `Counter()` and `OrderedDict()` in [library collections](https://docs.python.org/2/library/collections.html)):\n",
    " * ```python\n",
    "     def build_vocabulary(docs):\n",
    "        vocabulary = Counter()\n",
    "\n",
    "        for doc in docs:\n",
    "            words = doc.split()\n",
    "            vocabulary.update(words)\n",
    "\n",
    "        return OrderedDict(vocabulary.most_common())\n",
    " ```\n",
    "\n",
    "\n",
    "* Define a function to vectorize the documents, i.e., convert documents into a table where each line represents one document and the columns are the word counts.  \n",
    " * ```python\n",
    "     def vectorize(docs):\n",
    "        vocabulary = build_vocabulary()\n",
    "        vectors = []\n",
    "        for doc in docs:\n",
    "            vector = np.array([doc.count(word) for word in vocabulary])\n",
    "            vectors.append(vector)\n",
    "\n",
    "        return vectors\n",
    " ```\n",
    "\n",
    "* `docs_BOW = pd.DataFrame(vectorize(), columns=build_vocabulary())`  \n",
    "\n",
    "\n",
    "* Improvements to the bag of words representation:\n",
    " * Remove *stop words*\n",
    " * Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    " * nest\n",
    "\n",
    "**Or...**\n",
    "\n",
    "* use fsadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(docs):\n",
    "    vocabulary = Counter()\n",
    "\n",
    "    for doc in docs:\n",
    "        words = doc.split()\n",
    "        vocabulary.update(words)\n",
    "\n",
    "    return OrderedDict(vocabulary.most_common())\n",
    "\n",
    "def vectorize(docs):\n",
    "    vocabulary = build_vocabulary()\n",
    "    vectors = []\n",
    "    for doc in docs:\n",
    "        vector = np.array([doc.count(word) for word in vocabulary])\n",
    "        vectors.append(vector)\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instead of a `clean()` function define a sklearn `Class` with the clean function inside so we can call a `transform()` method to apply the cleaning to each document. In this way we can include this step in a **Pipeline**.  \n",
    "\n",
    "\n",
    "* Use sklearn [CountVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) instead of `build_vocabulary()` + `vectorize()`.  \n",
    "It receives an iterable of documents and returns a vectorized sparse matrix of token counts of those documents.  \n",
    "\n",
    "\n",
    "* Use sklearn [TfidfTransformer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html) to transform a count matrix to a normalized tf or tf-idf representation.  \n",
    "`CountVectorizer()` followed by `TfidfTransformer()` is equivalent to [TfidfVectorizer()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).  \n",
    "\n",
    "\n",
    "* next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Aldolpho (Steve Buscemi), an aspiring film mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>An unfunny, unworthy picture which is an undes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>A failure. The movie was just not good. It has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I saw this movie Sunday afternoon. I absolutel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Disney goes to the well one too many times as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Negative  Aldolpho (Steve Buscemi), an aspiring film mak...\n",
       "1  Negative  An unfunny, unworthy picture which is an undes...\n",
       "2  Negative  A failure. The movie was just not good. It has...\n",
       "3  Positive  I saw this movie Sunday afternoon. I absolutel...\n",
       "4  Negative  Disney goes to the well one too many times as ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./BLU07 - Feature Extraction/data/imdb_sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    5000 non-null object\n",
      "text         5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc,\n",
    "          regex_list = [(\"<[^>]*>\", \"\")], \n",
    "          tokenizer = WordPunctTokenizer(),\n",
    "          stemmer = SnowballStemmer(\"english\", ignore_stopwords=False)):\n",
    "    \n",
    "        \n",
    "    # Replace given regexes\n",
    "    for regex in regex_list:\n",
    "        doc = re.sub(regex[0], regex[1], doc)\n",
    "    \n",
    "    # lowercase\n",
    "    doc = doc.lower()\n",
    "    \n",
    "    # tokenize\n",
    "    words = tokenizer.tokenize(doc)\n",
    "    \n",
    "    # remove punctuation\n",
    "    words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "    \n",
    "    # stem\n",
    "    stems = list(map(stemmer.stem, words))\n",
    "    \n",
    "    new_doc = \" \".join(stems)\n",
    "    \n",
    "    return new_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A failure. The movie was just not good. It has humor that 5 year olds that will not even giggle at. I mean, sure, some parts were amusing, but most of it is not. Lindsey Lohan is a great actress (and a bad singer,) and she should be working on better movies. The movie should have been aired as a Disney Channel original movie, that is FREE.<br /><br />The only thing that was well done about this movie was the music. Nothing like a remade rock soundtrack to brighten up your day. These songs are so good. Especially Alyson and Amanda's Walking On Sunshine and Caleigh Peter's, Beach Boy song, Fun Fun Fun.<br /><br />4 out of 10. If I gave it a ten, 9 of that would be the music and 1 will be the movie. Not worth your money, but the soundtrack is.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a failur the movi was just not good it has humor that 5 year old that will not even giggl at i mean sure some part were amus but most of it is not lindsey lohan is a great actress and a bad singer ,) and she should be work on better movi the movi should have been air as a disney channel origin movi that is free the onli thing that was well done about this movi was the music noth like a remad rock soundtrack to brighten up your day these song are so good especi alyson and amanda s walk on sunshin and caleigh peter s beach boy song fun fun fun 4 out of 10 if i gave it a ten 9 of that would be the music and 1 will be the movi not worth your money but the soundtrack is'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[[2]].apply(clean)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a failure. the movi was just not good. it has humor that 5 year old that will not even giggl at. i mean, sure, some part were amusing, but most of it is not. lindsey lohan is a great actress (and a bad singer,) and she should be work on better movies. the movi should have been air as a disney channel origin movie, that is free.th onli thing that was well done about this movi was the music. noth like a remad rock soundtrack to brighten up your day. these song are so good. especi alyson and amanda walk on sunshin and caleigh peter's, beach boy song, fun fun fun.4 out of 10. if i gave it a ten, 9 of that would be the music and 1 will be the movie. not worth your money, but the soundtrack is.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_args = ([(\"<[^>]*>\", \"\")], \n",
    "              WhitespaceTokenizer(), \n",
    "              SnowballStemmer(\"english\"))\n",
    "\n",
    "df.text[[2]].apply(clean, args=clean_args)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP predictor - function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLP_get_predictions(X_train, y_train, X_test, y_test,\n",
    "                        vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=None),\n",
    "                        clf = MultinomialNB()):\n",
    "    '''Returns a fitted TfidfVectorizer and the test precision and recall on the 'spam' class\n",
    "       from a KNeighborsClassifier trained on the inputted train data\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (Series): Text data for training\n",
    "        y_train (Series): Labels corresponding to X_train\n",
    "        X_test (Series): Text data for testing\n",
    "        y_test (Series): Labels corresponding to X_test\n",
    "\n",
    "    Returns:\n",
    "        vectorizer (TfidfVectorizer): TfidfVectorizer with max_features == 50, fitted to X_train\n",
    "        precision (float): The precision score of the spam class on the test data from a\n",
    "                           KNeighborsClassifier fitted to the vectorized training data\n",
    "        recall (float): The recall score of the spam class on the test data from a\n",
    "                        KNeighborsClassifier fitted to the vectorized training data\n",
    "    '''\n",
    "    \n",
    "    # Fit the vectorizer to the train data    \n",
    "    vectorizer.fit(X_train)\n",
    "    \n",
    "    X_train_vect = vectorizer.transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "    \n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "    \n",
    "    \n",
    "    # Fit the classifier to the train data\n",
    "    clf.fit(X_train_vect, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test_vect)\n",
    "    \n",
    "    # Performance assessment\n",
    "    accuracy = np.mean(y_pred == y_test)    \n",
    "    #precision = precision_score(vect_y_test=='spam', pred=='spam')\n",
    "    #recall = recall_score(vect_y_test=='spam', pred=='spam')\n",
    "        \n",
    "    return y_pred, vectorizer, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].apply(clean), df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_funct, vectorizer, classifier = NLP_get_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.mean(y_pred_funct == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define class for Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to implement sentence cleaning\n",
    "class TextCleanerTransformer(TransformerMixin):\n",
    "    def __init__(self, tokenizer, stemmer, regex_list,\n",
    "                 lower=True, remove_punct=True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.regex_list = regex_list\n",
    "        self.lower = lower\n",
    "        self.remove_punct = remove_punct\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        X = list(map(self._clean_sentence, X))\n",
    "        return X\n",
    "    \n",
    "    def _clean_sentence(self, sentence):\n",
    "        \n",
    "        # Replace given regexes\n",
    "        for regex in self.regex_list:\n",
    "            sentence = re.sub(regex[0], regex[1], sentence)\n",
    "            \n",
    "        # lowercase\n",
    "        if self.lower:\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "        # Split sentence into list of words\n",
    "        words = self.tokenizer.tokenize(sentence)\n",
    "            \n",
    "        # Remove punctuation\n",
    "        if self.remove_punct:\n",
    "            words = list(filter(lambda x: x not in string.punctuation, words))\n",
    "\n",
    "        # Stem words\n",
    "        if self.stemmer:\n",
    "            words = map(self.stemmer.stem, words)\n",
    "\n",
    "        # Join list elements into string\n",
    "        sentence = \" \".join(words)\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['sentiment'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the Cleaner Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer and a stemmer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=False)\n",
    "regex_list = [(\"<[^>]*>\", \"\")]\n",
    "\n",
    "\n",
    "cleaner = TextCleanerTransformer(tokenizer, stemmer, regex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "text_clf = Pipeline([('stemm', cleaner),\n",
    "                     ('vect_tfidf', TfidfVectorizer(ngram_range=(1,1), stop_words=None)),\n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "y_pred_trans = text_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.856"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy = np.mean(y_pred == y_test)\n",
    "accuracy = np.mean(y_pred_trans == y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((y_pred_trans == 'Positive') != (y_pred_funct == 'Positive'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selction  \n",
    "\n",
    "* Truncated (see sklearn vectorizers `max_features` parameter).\n",
    "* Chi-squared (see [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) or [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html))\n",
    "* Singular Value Decomposition (see [TruncatedSVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html))\n",
    "* Principal Component Analysis (see [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit-learn [chi2](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vect type: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "X_train_vect.shape: (3500, 22659)\n",
      "\n",
      "chi_values type: <class 'numpy.ndarray'>\n",
      "chi_values shape: (22659,)\n"
     ]
    }
   ],
   "source": [
    "X_train_vect = vectorizer.transform(X_train)\n",
    "chi_values, p_values = chi2(X_train_vect, y_train)\n",
    "\n",
    "print(\"X_train_vect type: {}\".format(type(X_train_vect)))\n",
    "print(\"X_train_vect.shape: {}\".format(X_train_vect.shape))\n",
    "print(\"\\nchi_values type: {}\".format(type(chi_values)))\n",
    "print(\"chi_values shape: {}\".format(chi_values.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "feature_chi_series = pd.Series(chi_values, index=feature_names)\n",
    "\n",
    "feature_chi_series.dropna().sort_values(ascending=True)[-10:].plot.barh(figsize=(6,4), align='center', alpha=.2, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using scikit-learn [SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = vectorizer.transform(X_train)\n",
    "\n",
    "ch2_selector = SelectKBest(chi2, k=10)\n",
    "ch2_selector.fit(X_train_vect, y_train)\n",
    "\n",
    "X_train_vect_new = ch2_selector.transform(X_train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3500x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4566 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'crap', 'excellent', 'great', 'lame', 'no', 'nothing',\n",
       "       'poor', 'stupid', 'worst'], dtype='<U25')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = np.array(vectorizer.get_feature_names())[ch2_selector.get_support()]\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>crap</th>\n",
       "      <th>excellent</th>\n",
       "      <th>great</th>\n",
       "      <th>lame</th>\n",
       "      <th>no</th>\n",
       "      <th>nothing</th>\n",
       "      <th>poor</th>\n",
       "      <th>stupid</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bad  crap  excellent    great  lame        no  nothing  poor  stupid  \\\n",
       "0  0.000000   0.0        0.0  0.00000   0.0  0.000000      0.0   0.0     0.0   \n",
       "1  0.000000   0.0        0.0  0.00000   0.0  0.000000      0.0   0.0     0.0   \n",
       "2  0.080319   0.0        0.0  0.00000   0.0  0.000000      0.0   0.0     0.0   \n",
       "3  0.000000   0.0        0.0  0.00000   0.0  0.043004      0.0   0.0     0.0   \n",
       "4  0.050425   0.0        0.0  0.05012   0.0  0.045213      0.0   0.0     0.0   \n",
       "\n",
       "      worst  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.235556  \n",
       "3  0.000000  \n",
       "4  0.073941  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_vect_new.todense(), columns=new_features).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most frequent classifiers\n",
    "\n",
    "* [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html): `from sklearn.naive_bayes import MultinomialNB`\n",
    "* [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html): `from sklearn.neighbors import KNeighborsClassifier`  \n",
    "  Unlike the multinomial naive Bayes this classifier can handle negative numbers, useful after data transformations like SVD or PCA. This is a very good classifier with which to make a case for dimensionality reduction, since in a very high-dimensional space, the vector distances will most of the time be useless.\n",
    "* [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html): `from sklearn.ensemble import RandomForestClassifier`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra features using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Aldolpho (Steve Buscemi), an aspiring film mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>An unfunny, unworthy picture which is an undes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>A failure. The movie was just not good. It has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I saw this movie Sunday afternoon. I absolutel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Disney goes to the well one too many times as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Negative  Aldolpho (Steve Buscemi), an aspiring film mak...\n",
       "1  Negative  An unfunny, unworthy picture which is an undes...\n",
       "2  Negative  A failure. The movie was just not good. It has...\n",
       "3  Positive  I saw this movie Sunday afternoon. I absolutel...\n",
       "4  Negative  Disney goes to the well one too many times as ..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xf = df.copy()\n",
    "df_xf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete sentence lenght."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>nwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Aldolpho (Steve Buscemi), an aspiring film mak...</td>\n",
       "      <td>1214</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>An unfunny, unworthy picture which is an undes...</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>A failure. The movie was just not good. It has...</td>\n",
       "      <td>750</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I saw this movie Sunday afternoon. I absolutel...</td>\n",
       "      <td>698</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Disney goes to the well one too many times as ...</td>\n",
       "      <td>1331</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text   len  nwords\n",
       "0  Negative  Aldolpho (Steve Buscemi), an aspiring film mak...  1214     218\n",
       "1  Negative  An unfunny, unworthy picture which is an undes...   121      22\n",
       "2  Negative  A failure. The movie was just not good. It has...   750     145\n",
       "3  Positive  I saw this movie Sunday afternoon. I absolutel...   698     136\n",
       "4  Negative  Disney goes to the well one too many times as ...  1331     230"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xf['len'] = df_xf['text'].map(len)\n",
    "df_xf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_list = df_xf.hist(column='len', by='sentiment', bins=50,figsize=(12,4))\n",
    "ax_list[0].set_xlim((0,3000))\n",
    "ax_list[1].set_xlim((0,3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xf['nwords'] = df_xf['text'].str.split().map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>nwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1325.225255</td>\n",
       "      <td>234.852138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1366.011395</td>\n",
       "      <td>240.082515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   len      nwords\n",
       "sentiment                         \n",
       "Negative   1325.225255  234.852138\n",
       "Positive   1366.011395  240.082515"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xf.groupby('sentiment').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('the', 30675),\n",
       "             ('and', 17218),\n",
       "             ('a', 16316),\n",
       "             ('of', 15501),\n",
       "             ('to', 13453),\n",
       "             ('is', 11589),\n",
       "             ('in', 9357),\n",
       "             ('that', 6616),\n",
       "             ('I', 6460),\n",
       "             ('it', 5631),\n",
       "             ('this', 5305),\n",
       "             ('/><br', 5194),\n",
       "             ('as', 4968),\n",
       "             ('with', 4540),\n",
       "             ('was', 4368),\n",
       "             ('for', 4310),\n",
       "             ('but', 3442),\n",
       "             ('The', 3412),\n",
       "             ('his', 3348),\n",
       "             ('on', 3208),\n",
       "             ('are', 3049),\n",
       "             ('movie', 2861),\n",
       "             ('film', 2840),\n",
       "             ('you', 2672),\n",
       "             ('not', 2624),\n",
       "             ('have', 2526),\n",
       "             ('he', 2433),\n",
       "             ('by', 2414),\n",
       "             ('be', 2411),\n",
       "             ('one', 2211),\n",
       "             ('an', 2169),\n",
       "             ('at', 2111),\n",
       "             ('who', 2098),\n",
       "             ('from', 2044),\n",
       "             ('all', 1941),\n",
       "             ('has', 1894),\n",
       "             ('her', 1743),\n",
       "             ('like', 1703),\n",
       "             ('about', 1628),\n",
       "             ('they', 1577),\n",
       "             ('so', 1556),\n",
       "             ('very', 1545),\n",
       "             ('just', 1439),\n",
       "             ('out', 1433),\n",
       "             ('or', 1426),\n",
       "             ('more', 1418),\n",
       "             ('some', 1333),\n",
       "             ('This', 1267),\n",
       "             ('when', 1232),\n",
       "             ('good', 1201),\n",
       "             ('their', 1198),\n",
       "             ('what', 1194),\n",
       "             ('It', 1181),\n",
       "             ('my', 1130),\n",
       "             ('which', 1128),\n",
       "             ('can', 1126),\n",
       "             (\"it's\", 1085),\n",
       "             ('see', 1083),\n",
       "             ('would', 1063),\n",
       "             ('up', 1061),\n",
       "             ('really', 1048),\n",
       "             ('great', 1036),\n",
       "             ('-', 1030),\n",
       "             ('she', 1026),\n",
       "             ('only', 1014),\n",
       "             ('had', 1012),\n",
       "             ('will', 1004),\n",
       "             ('story', 992),\n",
       "             ('if', 975),\n",
       "             ('than', 960),\n",
       "             ('also', 934),\n",
       "             ('much', 915),\n",
       "             ('most', 914),\n",
       "             ('were', 910),\n",
       "             ('we', 890),\n",
       "             ('into', 882),\n",
       "             ('get', 874),\n",
       "             ('been', 866),\n",
       "             ('its', 847),\n",
       "             ('first', 832),\n",
       "             ('even', 828),\n",
       "             ('there', 828),\n",
       "             ('other', 814),\n",
       "             ('time', 782),\n",
       "             ('/>The', 778),\n",
       "             ('people', 772),\n",
       "             ('because', 751),\n",
       "             ('how', 750),\n",
       "             ('well', 734),\n",
       "             ('him', 728),\n",
       "             ('me', 726),\n",
       "             ('no', 724),\n",
       "             ('best', 698),\n",
       "             ('many', 695),\n",
       "             ('think', 694),\n",
       "             ('two', 680),\n",
       "             ('made', 678),\n",
       "             ('love', 669),\n",
       "             ('do', 664),\n",
       "             ('still', 656),\n",
       "             ('being', 654),\n",
       "             ('any', 633),\n",
       "             ('could', 630),\n",
       "             ('never', 630),\n",
       "             ('way', 629),\n",
       "             ('make', 627),\n",
       "             (\"don't\", 624),\n",
       "             ('But', 612),\n",
       "             ('little', 611),\n",
       "             ('where', 579),\n",
       "             ('seen', 573),\n",
       "             ('<br', 570),\n",
       "             ('show', 560),\n",
       "             ('it.', 553),\n",
       "             ('them', 547),\n",
       "             ('such', 547),\n",
       "             ('does', 537),\n",
       "             ('after', 535),\n",
       "             ('know', 533),\n",
       "             (\"It's\", 527),\n",
       "             ('And', 523),\n",
       "             ('character', 521),\n",
       "             ('too', 517),\n",
       "             ('A', 515),\n",
       "             ('watch', 514),\n",
       "             ('did', 511),\n",
       "             ('characters', 508),\n",
       "             ('life', 504),\n",
       "             ('He', 503),\n",
       "             ('movies', 502),\n",
       "             ('your', 498),\n",
       "             ('then', 496),\n",
       "             ('In', 496),\n",
       "             ('those', 496),\n",
       "             ('films', 489),\n",
       "             ('over', 480),\n",
       "             ('these', 473),\n",
       "             ('makes', 465),\n",
       "             ('quite', 463),\n",
       "             ('real', 452),\n",
       "             ('film.', 451),\n",
       "             ('find', 448),\n",
       "             ('ever', 446),\n",
       "             ('movie.', 444),\n",
       "             ('back', 443),\n",
       "             ('i', 437),\n",
       "             ('say', 431),\n",
       "             ('man', 428),\n",
       "             ('better', 422),\n",
       "             ('should', 417),\n",
       "             ('off', 415),\n",
       "             ('young', 414),\n",
       "             ('between', 412),\n",
       "             ('lot', 411),\n",
       "             ('through', 407),\n",
       "             ('years', 406),\n",
       "             ('go', 403),\n",
       "             ('same', 400),\n",
       "             ('film,', 398),\n",
       "             ('always', 389),\n",
       "             ('may', 389),\n",
       "             (\"doesn't\", 387),\n",
       "             ('scene', 381),\n",
       "             ('while', 380),\n",
       "             ('something', 378),\n",
       "             ('few', 375),\n",
       "             ('both', 374),\n",
       "             (\"didn't\", 368),\n",
       "             ('own', 368),\n",
       "             ('every', 368),\n",
       "             ('plot', 368),\n",
       "             ('watching', 359),\n",
       "             ('acting', 359),\n",
       "             ('new', 359),\n",
       "             ('scenes', 357),\n",
       "             ('old', 354),\n",
       "             ('/>I', 351),\n",
       "             ('If', 351),\n",
       "             ('bit', 349),\n",
       "             ('movie,', 341),\n",
       "             ('going', 340),\n",
       "             (\"I'm\", 335),\n",
       "             ('actually', 335),\n",
       "             ('cast', 331),\n",
       "             ('give', 329),\n",
       "             ('bad', 328),\n",
       "             ('each', 327),\n",
       "             ('without', 325),\n",
       "             ('end', 323),\n",
       "             ('another', 321),\n",
       "             ('performance', 320),\n",
       "             ('gets', 320),\n",
       "             ('before', 318),\n",
       "             ('almost', 317),\n",
       "             ('things', 316),\n",
       "             ('got', 316),\n",
       "             ('why', 316),\n",
       "             ('&', 316),\n",
       "             ('want', 313),\n",
       "             ('There', 313),\n",
       "             ('As', 311),\n",
       "             ('series', 311),\n",
       "             ('though', 310),\n",
       "             ('actors', 310),\n",
       "             ('saw', 307),\n",
       "             ('family', 307),\n",
       "             ('look', 306),\n",
       "             (\"I've\", 305),\n",
       "             ('part', 305),\n",
       "             ('seems', 303),\n",
       "             ('our', 295),\n",
       "             ('pretty', 295),\n",
       "             (\"can't\", 294),\n",
       "             ('here', 294),\n",
       "             ('us', 293),\n",
       "             ('around', 287),\n",
       "             ('feel', 286),\n",
       "             ('last', 284),\n",
       "             ('take', 282),\n",
       "             ('role', 282),\n",
       "             ('must', 281),\n",
       "             ('work', 279),\n",
       "             (\"isn't\", 277),\n",
       "             ('She', 277),\n",
       "             ('it,', 275),\n",
       "             ('come', 275),\n",
       "             ('long', 275),\n",
       "             ('excellent', 275),\n",
       "             ('whole', 274),\n",
       "             ('thought', 274),\n",
       "             ('played', 272),\n",
       "             ('thing', 268),\n",
       "             ('/>This', 268),\n",
       "             ('right', 267),\n",
       "             ('rather', 266),\n",
       "             ('\"The', 265),\n",
       "             ('now', 265),\n",
       "             ('action', 263),\n",
       "             ('takes', 261),\n",
       "             ('big', 260),\n",
       "             ('especially', 259),\n",
       "             ('funny', 258),\n",
       "             ('different', 257),\n",
       "             ('plays', 257),\n",
       "             ('might', 257),\n",
       "             ('comes', 255),\n",
       "             ('probably', 254),\n",
       "             ('director', 254),\n",
       "             ('since', 254),\n",
       "             ('shows', 253),\n",
       "             ('found', 253),\n",
       "             ('fact', 252),\n",
       "             ('down', 246),\n",
       "             ('am', 246),\n",
       "             ('They', 246),\n",
       "             ('When', 244),\n",
       "             ('John', 244),\n",
       "             ('world', 241),\n",
       "             ('fun', 239),\n",
       "             ('watched', 238),\n",
       "             ('yet', 236),\n",
       "             ('original', 234),\n",
       "             ('beautiful', 233),\n",
       "             ('true', 233),\n",
       "             ('interesting', 231),\n",
       "             ('music', 230),\n",
       "             ('American', 229),\n",
       "             ('play', 228),\n",
       "             ('worth', 228),\n",
       "             ('done', 227),\n",
       "             ('making', 227),\n",
       "             ('You', 224),\n",
       "             ('kind', 221),\n",
       "             ('far', 220),\n",
       "             ('enough', 220),\n",
       "             ('seem', 219),\n",
       "             ('anyone', 217),\n",
       "             ('hard', 216),\n",
       "             ('TV', 216),\n",
       "             ('times', 215),\n",
       "             ('horror', 211),\n",
       "             ('What', 210),\n",
       "             ('came', 209),\n",
       "             ('trying', 209),\n",
       "             ('woman', 209),\n",
       "             ('main', 209),\n",
       "             ('having', 208),\n",
       "             ('goes', 207),\n",
       "             ('comedy', 207),\n",
       "             ('time.', 206),\n",
       "             ('away', 206),\n",
       "             ('version', 204),\n",
       "             ('wonderful', 204),\n",
       "             ('sure', 203),\n",
       "             (\"that's\", 203),\n",
       "             ('during', 201),\n",
       "             ('recommend', 201),\n",
       "             ('once', 200),\n",
       "             ('set', 198),\n",
       "             (\"he's\", 197),\n",
       "             ('perfect', 197),\n",
       "             ('put', 197),\n",
       "             ('truly', 195),\n",
       "             ('favorite', 194),\n",
       "             ('least', 193),\n",
       "             ('gives', 193),\n",
       "             ('small', 192),\n",
       "             ('enjoy', 192),\n",
       "             ('One', 191),\n",
       "             ('job', 191),\n",
       "             ('himself', 191),\n",
       "             ('definitely', 190),\n",
       "             ('day', 190),\n",
       "             ('become', 188),\n",
       "             ('left', 187),\n",
       "             ('again', 187),\n",
       "             ('nothing', 186),\n",
       "             ('nice', 186),\n",
       "             ('less', 185),\n",
       "             ('point', 185),\n",
       "             ('used', 185),\n",
       "             ('My', 184),\n",
       "             ('place', 184),\n",
       "             ('three', 184),\n",
       "             ('DVD', 184),\n",
       "             ('help', 184),\n",
       "             ('girl', 184),\n",
       "             ('father', 184),\n",
       "             ('looking', 184),\n",
       "             ('loved', 181),\n",
       "             ('until', 181),\n",
       "             ('human', 180),\n",
       "             ('liked', 180),\n",
       "             ('anything', 180),\n",
       "             ('.', 180),\n",
       "             ('looks', 179),\n",
       "             ('performances', 179),\n",
       "             ('later', 178),\n",
       "             ('(and', 176),\n",
       "             ('That', 176),\n",
       "             ('remember', 175),\n",
       "             ('His', 173),\n",
       "             ('second', 172),\n",
       "             ('Hollywood', 172),\n",
       "             ('keep', 172),\n",
       "             ('However,', 171),\n",
       "             ('classic', 170),\n",
       "             ('amazing', 170),\n",
       "             ('early', 170),\n",
       "             ('For', 169),\n",
       "             ('against', 168),\n",
       "             ('high', 168),\n",
       "             ('everything', 165),\n",
       "             ('given', 165),\n",
       "             ('time,', 165),\n",
       "             ('believe', 165),\n",
       "             ('although', 165),\n",
       "             ('enjoyed', 163),\n",
       "             ('ending', 163),\n",
       "             ('use', 163),\n",
       "             ('read', 162),\n",
       "             ('So', 161),\n",
       "             ('wife', 161),\n",
       "             ('playing', 161),\n",
       "             ('need', 160),\n",
       "             ('actor', 160),\n",
       "             ('often', 159),\n",
       "             ('seeing', 159),\n",
       "             ('together', 158),\n",
       "             ('live', 158),\n",
       "             ('couple', 158),\n",
       "             ('--', 157),\n",
       "             ('full', 157),\n",
       "             ('Michael', 157),\n",
       "             ('tell', 156),\n",
       "             ('special', 155),\n",
       "             ('simply', 155),\n",
       "             ('We', 154),\n",
       "             ('sense', 154),\n",
       "             ('THE', 153),\n",
       "             ('guy', 152),\n",
       "             ('short', 152),\n",
       "             (\"wasn't\", 152),\n",
       "             ('said', 151),\n",
       "             ('along', 151),\n",
       "             ('becomes', 150),\n",
       "             ('course', 150),\n",
       "             ('production', 149),\n",
       "             ('New', 148),\n",
       "             ('try', 147),\n",
       "             ('All', 145),\n",
       "             ('behind', 145),\n",
       "             (\"you're\", 144),\n",
       "             ('is,', 143),\n",
       "             ('audience', 143),\n",
       "             ('several', 142),\n",
       "             ('everyone', 142),\n",
       "             ('getting', 141),\n",
       "             ('idea', 141),\n",
       "             ('year', 141),\n",
       "             ('based', 141),\n",
       "             ('someone', 140),\n",
       "             ('life.', 140),\n",
       "             ('all,', 140),\n",
       "             ('felt', 139),\n",
       "             ('him.', 139),\n",
       "             ('highly', 139),\n",
       "             ('lives', 138),\n",
       "             ('hope', 138),\n",
       "             ('top', 138),\n",
       "             ('certainly', 137),\n",
       "             ('able', 137),\n",
       "             ('let', 137),\n",
       "             ('(the', 136),\n",
       "             ('turns', 136),\n",
       "             ('entire', 136),\n",
       "             ('Not', 135),\n",
       "             ('late', 135),\n",
       "             ('that,', 135),\n",
       "             ('\\x96', 135),\n",
       "             ('game', 134),\n",
       "             ('next', 133),\n",
       "             ('book', 133),\n",
       "             ('episode', 133),\n",
       "             ('10', 133),\n",
       "             ('well.', 132),\n",
       "             ('start', 132),\n",
       "             ('friends', 131),\n",
       "             ('went', 131),\n",
       "             ('rest', 131),\n",
       "             ('Mr.', 131),\n",
       "             ('absolutely', 130),\n",
       "             ('shot', 129),\n",
       "             (\"film's\", 129),\n",
       "             (\"there's\", 129),\n",
       "             ('At', 128),\n",
       "             ('understand', 128),\n",
       "             ('boy', 128),\n",
       "             ('screen', 128),\n",
       "             ('women', 128),\n",
       "             ('story,', 127),\n",
       "             ('Of', 127),\n",
       "             ('maybe', 127),\n",
       "             ('sometimes', 127),\n",
       "             ('fan', 126),\n",
       "             ('While', 126),\n",
       "             ('home', 126),\n",
       "             ('completely', 125),\n",
       "             ('finally', 125),\n",
       "             ('script', 125),\n",
       "             ('drama', 125),\n",
       "             ('half', 123),\n",
       "             ('works', 123),\n",
       "             ('final', 123),\n",
       "             ('reason', 123),\n",
       "             ('gave', 123),\n",
       "             ('minutes', 122),\n",
       "             ('title', 122),\n",
       "             ('moments', 121),\n",
       "             ('shown', 121),\n",
       "             ('whose', 121),\n",
       "             ('stories', 120),\n",
       "             ('style', 120),\n",
       "             ('them.', 119),\n",
       "             ('already', 119),\n",
       "             ('viewer', 119),\n",
       "             ('star', 119),\n",
       "             ('stars', 119),\n",
       "             ('good.', 118),\n",
       "             ('With', 117),\n",
       "             ('brilliant', 117),\n",
       "             (\"won't\", 117),\n",
       "             ('written', 116),\n",
       "             ('turn', 116),\n",
       "             ('others', 116),\n",
       "             ('wants', 116),\n",
       "             ('fans', 116),\n",
       "             ('face', 116),\n",
       "             ('known', 116),\n",
       "             ('musical', 116),\n",
       "             ('strong', 115),\n",
       "             ('school', 115),\n",
       "             ('expect', 115),\n",
       "             ('relationship', 114),\n",
       "             ('men', 114),\n",
       "             ('romantic', 114),\n",
       "             ('mind', 113),\n",
       "             ('course,', 113),\n",
       "             ('kids', 113),\n",
       "             ('After', 113),\n",
       "             ('beginning', 113),\n",
       "             ('wanted', 113),\n",
       "             ('me.', 113),\n",
       "             ('number', 113),\n",
       "             ('effects', 112),\n",
       "             ('soon', 112),\n",
       "             ('Even', 112),\n",
       "             (\"she's\", 112),\n",
       "             ('night', 112),\n",
       "             ('called', 112),\n",
       "             ('tells', 111),\n",
       "             ('care', 111),\n",
       "             ('house', 111),\n",
       "             ('story.', 111),\n",
       "             ('Although', 110),\n",
       "             ('entertaining', 110),\n",
       "             ('Paul', 110),\n",
       "             ('doing', 110),\n",
       "             ('supporting', 110),\n",
       "             ('To', 109),\n",
       "             ('/>It', 108),\n",
       "             ('particularly', 108),\n",
       "             ('death', 108),\n",
       "             ('modern', 108),\n",
       "             ('past', 108),\n",
       "             ('me,', 108),\n",
       "             ('friend', 108),\n",
       "             ('fine', 108),\n",
       "             ('chance', 108),\n",
       "             ('video', 108),\n",
       "             ('including', 107),\n",
       "             ('piece', 107),\n",
       "             ('lead', 107),\n",
       "             (\"I'd\", 107),\n",
       "             ('perhaps', 107),\n",
       "             ('dark', 107),\n",
       "             ('finds', 107),\n",
       "             ('Some', 106),\n",
       "             ('tries', 106),\n",
       "             ('heart', 105),\n",
       "             ('enjoyable', 105),\n",
       "             ('British', 105),\n",
       "             ('taken', 105),\n",
       "             (\"you'll\", 105),\n",
       "             ('totally', 104),\n",
       "             ('somewhat', 104),\n",
       "             ('voice', 103),\n",
       "             ('starts', 103),\n",
       "             ('son', 103),\n",
       "             ('town', 103),\n",
       "             ('under', 103),\n",
       "             ('greatest', 102),\n",
       "             ('score', 102),\n",
       "             ('events', 102),\n",
       "             ('person', 102),\n",
       "             ('line', 102),\n",
       "             ('lost', 101),\n",
       "             ('war', 101),\n",
       "             ('took', 101),\n",
       "             ('simple', 100),\n",
       "             ('picture', 100),\n",
       "             ('life,', 100),\n",
       "             ('told', 99),\n",
       "             ('history', 99),\n",
       "             ('leave', 99),\n",
       "             ('James', 99),\n",
       "             ('moving', 99),\n",
       "             ('moment', 99),\n",
       "             ('heard', 99),\n",
       "             ('throughout', 99),\n",
       "             ('important', 99),\n",
       "             ('black', 98),\n",
       "             ('case', 98),\n",
       "             ('Robert', 98),\n",
       "             ('similar', 98),\n",
       "             ('sort', 98),\n",
       "             ('laugh', 97),\n",
       "             ('instead', 97),\n",
       "             ('despite', 97),\n",
       "             (',', 97),\n",
       "             ('seemed', 97),\n",
       "             ('/>A', 97),\n",
       "             ('feeling', 97),\n",
       "             ('extremely', 96),\n",
       "             ('good,', 96),\n",
       "             ('name', 96),\n",
       "             ('/>In', 96),\n",
       "             ('Jack', 95),\n",
       "             ('song', 94),\n",
       "             ('superb', 94),\n",
       "             ('giving', 94),\n",
       "             ('quality', 94),\n",
       "             ('genre', 94),\n",
       "             ('bring', 94),\n",
       "             ('humor', 94),\n",
       "             ('Tom', 94),\n",
       "             ('mother', 94),\n",
       "             ('sound', 94),\n",
       "             ('Japanese', 93),\n",
       "             ('local', 93),\n",
       "             (\"I'll\", 93),\n",
       "             ('however,', 93),\n",
       "             ('head', 93),\n",
       "             ('certain', 93),\n",
       "             ('and,', 93),\n",
       "             ('exactly', 93),\n",
       "             ('wrong', 92),\n",
       "             ('2', 92),\n",
       "             ('cannot', 92),\n",
       "             ('direction', 92),\n",
       "             ('taking', 92),\n",
       "             ('easy', 92),\n",
       "             ('hit', 92),\n",
       "             ('money', 92),\n",
       "             ('opening', 91),\n",
       "             ('No', 91),\n",
       "             ('him,', 91),\n",
       "             ('themselves', 91),\n",
       "             ('well,', 91),\n",
       "             ('nearly', 91),\n",
       "             ('thinking', 91),\n",
       "             ('episodes', 91),\n",
       "             ('released', 91),\n",
       "             ('Oscar', 91),\n",
       "             ('change', 90),\n",
       "             ('says', 90),\n",
       "             ('English', 90),\n",
       "             ('David', 90),\n",
       "             ('feels', 90),\n",
       "             ('light', 90),\n",
       "             (\"who's\", 90),\n",
       "             ('happy', 90),\n",
       "             ('brings', 90),\n",
       "             ('famous', 90),\n",
       "             ('usual', 90),\n",
       "             ('run', 89),\n",
       "             ('view', 89),\n",
       "             ('children', 89),\n",
       "             ('this,', 89),\n",
       "             ('parts', 88),\n",
       "             (\"/>It's\", 88),\n",
       "             ('wish', 88),\n",
       "             ('one.', 88),\n",
       "             ('living', 88),\n",
       "             ('comic', 87),\n",
       "             (\"couldn't\", 87),\n",
       "             ('Just', 87),\n",
       "             ('personal', 87),\n",
       "             ('various', 87),\n",
       "             ('brought', 87),\n",
       "             ('side', 87),\n",
       "             ('brother', 87),\n",
       "             ('attention', 86),\n",
       "             ('/>But', 86),\n",
       "             ('Richard', 86),\n",
       "             ('way,', 86),\n",
       "             ('eyes', 86),\n",
       "             ('days', 86),\n",
       "             ('working', 86),\n",
       "             ('camera', 85),\n",
       "             (\"There's\", 85),\n",
       "             ('happen', 85),\n",
       "             ('itself', 85),\n",
       "             ('theme', 85),\n",
       "             ('/>As', 84),\n",
       "             ('here,', 84),\n",
       "             ('act', 84),\n",
       "             ('needs', 84),\n",
       "             ('experience', 84),\n",
       "             ('meets', 84),\n",
       "             ('Best', 84),\n",
       "             ('else', 84),\n",
       "             ('lack', 83),\n",
       "             ('cinematography', 83),\n",
       "             ('either', 83),\n",
       "             ('soundtrack', 83),\n",
       "             ('mostly', 83),\n",
       "             ('Peter', 83),\n",
       "             ('matter', 82),\n",
       "             ('out.', 82),\n",
       "             ('songs', 82),\n",
       "             ('art', 82),\n",
       "             ('begins', 82),\n",
       "             ('typical', 82),\n",
       "             ('killer', 82),\n",
       "             ('husband', 82),\n",
       "             ('turned', 82),\n",
       "             ('fact,', 82),\n",
       "             ('problem', 81),\n",
       "             ('coming', 81),\n",
       "             ('four', 81),\n",
       "             ('across', 81),\n",
       "             ('type', 81),\n",
       "             ('documentary', 81),\n",
       "             ('actress', 81),\n",
       "             ('murder', 81),\n",
       "             ('problems', 81),\n",
       "             ('evil', 81),\n",
       "             ('films,', 81),\n",
       "             ('fight', 81),\n",
       "             ('started', 81),\n",
       "             ('upon', 80),\n",
       "             ('white', 80),\n",
       "             ('keeps', 80),\n",
       "             ('sets', 80),\n",
       "             ('fantastic', 80),\n",
       "             ('character,', 80),\n",
       "             ('(as', 80),\n",
       "             ('directed', 80),\n",
       "             ('learn', 80),\n",
       "             ('easily', 80),\n",
       "             ('/>If', 80),\n",
       "             ('that.', 80),\n",
       "             ('lines', 80),\n",
       "             ('knows', 79),\n",
       "             ('emotional', 79),\n",
       "             ('George', 79),\n",
       "             ('funny,', 79),\n",
       "             ('leaves', 79),\n",
       "             ('hear', 79),\n",
       "             (\"haven't\", 78),\n",
       "             ('whether', 78),\n",
       "             ('dialogue', 78),\n",
       "             ('Jane', 78),\n",
       "             ('group', 78),\n",
       "             ('movies.', 78),\n",
       "             ('involved', 78),\n",
       "             ('except', 78),\n",
       "             ('York', 78),\n",
       "             ('her.', 78),\n",
       "             ('difficult', 77),\n",
       "             ('example', 77),\n",
       "             ('talking', 77),\n",
       "             ('among', 77),\n",
       "             ('film.<br', 77),\n",
       "             ('order', 77),\n",
       "             ('due', 77),\n",
       "             ('dead', 77),\n",
       "             ('Her', 77),\n",
       "             ('characters,', 77),\n",
       "             ('police', 76),\n",
       "             ('happened', 76),\n",
       "             ('cinema', 76),\n",
       "             ('close', 76),\n",
       "             ('surprised', 76),\n",
       "             ('sequence', 76),\n",
       "             ('mean', 75),\n",
       "             ('falls', 75),\n",
       "             ('clearly', 75),\n",
       "             ('above', 75),\n",
       "             ('actual', 75),\n",
       "             ('sex', 75),\n",
       "             ('ones', 75),\n",
       "             ('one,', 75),\n",
       "             ('Joe', 75),\n",
       "             ('herself', 75),\n",
       "             ('particular', 75),\n",
       "             (\"they're\", 75),\n",
       "             ('end,', 75),\n",
       "             ('towards', 75),\n",
       "             ('kept', 75),\n",
       "             ('too.', 74),\n",
       "             ('it.<br', 74),\n",
       "             ('all.', 74),\n",
       "             ('plenty', 74),\n",
       "             ('knew', 74),\n",
       "             ('power', 74),\n",
       "             ('thriller', 74),\n",
       "             ('writing', 74),\n",
       "             ('future', 74),\n",
       "             ('appears', 74),\n",
       "             ('single', 74),\n",
       "             ('serious', 74),\n",
       "             ('How', 74),\n",
       "             ('overall', 74),\n",
       "             ('end.', 74),\n",
       "             ('3', 74),\n",
       "             ('female', 74),\n",
       "             ('Ben', 73),\n",
       "             ('powerful', 73),\n",
       "             ('memorable', 73),\n",
       "             ('way.', 73),\n",
       "             ('unique', 73),\n",
       "             ('feature', 73),\n",
       "             ('manages', 73),\n",
       "             ('became', 73),\n",
       "             ('won', 73),\n",
       "             ('From', 73),\n",
       "             ('On', 73),\n",
       "             ('ends', 73),\n",
       "             ('Charlie', 73),\n",
       "             ('solid', 73),\n",
       "             ('perfectly', 72),\n",
       "             ('leads', 72),\n",
       "             ('car', 72),\n",
       "             ('move', 72),\n",
       "             ('forget', 72),\n",
       "             ('William', 72),\n",
       "             ('nature', 72),\n",
       "             ('show.', 72),\n",
       "             ('supposed', 72),\n",
       "             ('atmosphere', 72),\n",
       "             ('/>', 72),\n",
       "             ('season', 72),\n",
       "             ('huge', 71),\n",
       "             ('class', 71),\n",
       "             ('These', 71),\n",
       "             ('copy', 71),\n",
       "             ('low', 71),\n",
       "             ('features', 71),\n",
       "             ('within', 71),\n",
       "             ('animation', 71),\n",
       "             ('kill', 70),\n",
       "             ('sees', 70),\n",
       "             ('portrayed', 70),\n",
       "             ('elements', 70),\n",
       "             ('five', 70),\n",
       "             ('budget', 70),\n",
       "             ('happens', 70),\n",
       "             ('realistic', 70),\n",
       "             ('figure', 70),\n",
       "             ('out,', 70),\n",
       "             ('here.', 69),\n",
       "             ('viewing', 69),\n",
       "             ('Man', 69),\n",
       "             ('Great', 69),\n",
       "             ('message', 69),\n",
       "             ('create', 69),\n",
       "             ('save', 69),\n",
       "             ('hand', 69),\n",
       "             ('usually', 69),\n",
       "             ('Most', 69),\n",
       "             ('age', 69),\n",
       "             ('hate', 69),\n",
       "             ('Now', 69),\n",
       "             ('this.', 69),\n",
       "             ('child', 69),\n",
       "             ('fall', 69),\n",
       "             ('stuff', 68),\n",
       "             ('deal', 68),\n",
       "             ('obvious', 68),\n",
       "             ('team', 68),\n",
       "             ('watch.', 68),\n",
       "             ('beauty', 68),\n",
       "             ('believable', 68),\n",
       "             ('Disney', 68),\n",
       "             ('lots', 68),\n",
       "             ('hold', 68),\n",
       "             ('Ann', 68),\n",
       "             ('again.', 68),\n",
       "             ('strange', 67),\n",
       "             ('again,', 67),\n",
       "             ('sad', 67),\n",
       "             ('(who', 67),\n",
       "             ('An', 67),\n",
       "             ('running', 67),\n",
       "             ('points', 67),\n",
       "             ('Also', 67),\n",
       "             ('hilarious', 67),\n",
       "             ('guess', 67),\n",
       "             ('eventually', 67),\n",
       "             ('add', 66),\n",
       "             ('/>There', 66),\n",
       "             ('reality', 66),\n",
       "             ('violence', 66),\n",
       "             ('fairly', 66),\n",
       "             ('follow', 66),\n",
       "             (\"aren't\", 66),\n",
       "             ('myself', 66),\n",
       "             ('named', 66),\n",
       "             ('earlier', 66),\n",
       "             ('begin', 66),\n",
       "             ('Stewart', 66),\n",
       "             ('show,', 66),\n",
       "             ('years.', 66),\n",
       "             ('/>And', 66),\n",
       "             ('beyond', 66),\n",
       "             ('leading', 66),\n",
       "             ('roles', 66),\n",
       "             ('tale', 66),\n",
       "             ('release', 66),\n",
       "             ('visual', 65),\n",
       "             ('nor', 65),\n",
       "             ('interest', 65),\n",
       "             ('city', 65),\n",
       "             ('major', 65),\n",
       "             ('deep', 65),\n",
       "             ('previous', 65),\n",
       "             ('subject', 65),\n",
       "             ('portrayal', 65),\n",
       "             ('dance', 65),\n",
       "             (\"wouldn't\", 65),\n",
       "             ('slow', 65),\n",
       "             ('movie.<br', 65),\n",
       "             ('stand', 64),\n",
       "             ('guys', 64),\n",
       "             ('social', 64),\n",
       "             ('films.', 64),\n",
       "             ('French', 64),\n",
       "             ('screen.', 64),\n",
       "             ('present', 64),\n",
       "             ('movies,', 64),\n",
       "             ('however', 64),\n",
       "             ('country', 64),\n",
       "             ('decided', 64),\n",
       "             ('middle', 63),\n",
       "             ('(a', 63),\n",
       "             ('Is', 63),\n",
       "             ('showing', 63),\n",
       "             ('talent', 63),\n",
       "             ('(which', 63),\n",
       "             ('rich', 63),\n",
       "             ('realize', 63),\n",
       "             ('career', 63),\n",
       "             ('buy', 63),\n",
       "             ('wonder', 63),\n",
       "             ('near', 63),\n",
       "             ('mystery', 63),\n",
       "             ('stop', 63),\n",
       "             ('review', 63),\n",
       "             ('talk', 63),\n",
       "             ('interested', 63),\n",
       "             ('though,', 63),\n",
       "             ('uses', 62),\n",
       "             ('mention', 62),\n",
       "             ('obviously', 62),\n",
       "             ('complete', 62),\n",
       "             ('familiar', 62),\n",
       "             ('compared', 62),\n",
       "             ('subtle', 62),\n",
       "             ('viewers', 62),\n",
       "             ('stage', 62),\n",
       "             ('remains', 62),\n",
       "             ('seen.', 62),\n",
       "             ('whom', 62),\n",
       "             ('poor', 61),\n",
       "             ('incredible', 61),\n",
       "             ('opinion', 61),\n",
       "             ('looked', 61),\n",
       "             ('deserves', 61),\n",
       "             ('telling', 61),\n",
       "             ('characters.', 61),\n",
       "             ('dramatic', 61),\n",
       "             ('crime', 61),\n",
       "             ('role.', 61),\n",
       "             ('recently', 61),\n",
       "             ('decides', 61),\n",
       "             ('Red', 61),\n",
       "             ('room', 61),\n",
       "             ('alone', 61),\n",
       "             ('saying', 60),\n",
       "             ('setting', 60),\n",
       "             ('pure', 60),\n",
       "             ('straight', 60),\n",
       "             ('Then', 60),\n",
       "             ('sexual', 60),\n",
       "             ('possible', 60),\n",
       "             ('girls', 60),\n",
       "             ('using', 60),\n",
       "             ('Maybe', 60),\n",
       "             ('form', 60),\n",
       "             ('singing', 60),\n",
       "             ('Well,', 59),\n",
       "             ('them,', 59),\n",
       "             ('Its', 59),\n",
       "             ('box', 59),\n",
       "             (\"'The\", 59),\n",
       "             ('starring', 59),\n",
       "             ('her,', 59),\n",
       "             ('band', 59),\n",
       "             ('By', 59),\n",
       "             ('business', 59),\n",
       "             ('more.', 59),\n",
       "             ('leaving', 59),\n",
       "             ('Like', 59),\n",
       "             ('great.', 59),\n",
       "             ('adult', 59),\n",
       "             ('up.', 59),\n",
       "             ('appreciate', 59),\n",
       "             ('wonderfully', 59),\n",
       "             ('natural', 58),\n",
       "             ('is.', 58),\n",
       "             ('political', 58),\n",
       "             ('Scott', 58),\n",
       "             ('great,', 58),\n",
       "             ('acting,', 58),\n",
       "             ('effect', 58),\n",
       "             ('(I', 58),\n",
       "             ('decent', 58),\n",
       "             ('basically', 58),\n",
       "             ('world.', 58),\n",
       "             ('following', 58),\n",
       "             ('scenes,', 58),\n",
       "             ('eye', 57),\n",
       "             ('cool', 57),\n",
       "             ('body', 57),\n",
       "             (\"you've\", 57),\n",
       "             ('shots', 57),\n",
       "             ('on.', 57),\n",
       "             ('plot,', 57),\n",
       "             (\"He's\", 57),\n",
       "             ('younger', 57),\n",
       "             ('daughter', 57),\n",
       "             ('hours', 57),\n",
       "             ('moves', 57),\n",
       "             ('terrific', 57),\n",
       "             ('aspect', 57),\n",
       "             ('(or', 56),\n",
       "             ('kid', 56),\n",
       "             ('caught', 56),\n",
       "             ...])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_common_words = build_vocabulary(df_xf[df.sentiment == 'Positive'].text)\n",
    "positive_common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the medium-sized SpaCy model\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of SpaCy \"Docs\" by leveraging the SpaCy pipeline\n",
    "docs = list(nlp.pipe(df_xf['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting verbs: 1st option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_verbs = []\n",
    "\n",
    "for doc in docs:\n",
    "    \n",
    "    verbs_count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verbs_count += 1\n",
    "            \n",
    "    n_verbs.append(verbs_count)\n",
    "     \n",
    "df_xf['n_verbs1'] = n_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting verbs: 2nd option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "verb_counts = []\n",
    "verbs = []\n",
    "\n",
    "pattern = [{\"POS\": \"VERB\"}]\n",
    "matcher.add('verbs', None, pattern)\n",
    "\n",
    "for doc in docs:\n",
    "    matches = matcher(doc)\n",
    "    # Number of verbs\n",
    "    verb_counts.append(len(matches))\n",
    "    verbs_in_doc = []\n",
    "    # List of verbs for each doc\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]  # the matched span\n",
    "        span_text = span.text  # the span as a string\n",
    "        verbs_in_doc.append(span_text)\n",
    "    verbs.append(verbs_in_doc)\n",
    "\n",
    "df_xf['n_verbs2'] = verb_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>nwords</th>\n",
       "      <th>n_verbs1</th>\n",
       "      <th>n_verbs2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>1325.225255</td>\n",
       "      <td>234.852138</td>\n",
       "      <td>25.876578</td>\n",
       "      <td>25.876578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>1366.011395</td>\n",
       "      <td>240.082515</td>\n",
       "      <td>24.863654</td>\n",
       "      <td>24.863654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   len      nwords   n_verbs1   n_verbs2\n",
       "sentiment                                               \n",
       "Negative   1325.225255  234.852138  25.876578  25.876578\n",
       "Positive   1366.011395  240.082515  24.863654  24.863654"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xf.groupby('sentiment').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>nwords</th>\n",
       "      <th>n_verbs1</th>\n",
       "      <th>n_verbs2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Aldolpho (Steve Buscemi), an aspiring film mak...</td>\n",
       "      <td>1214</td>\n",
       "      <td>218</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>An unfunny, unworthy picture which is an undes...</td>\n",
       "      <td>121</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>A failure. The movie was just not good. It has...</td>\n",
       "      <td>750</td>\n",
       "      <td>145</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I saw this movie Sunday afternoon. I absolutel...</td>\n",
       "      <td>698</td>\n",
       "      <td>136</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Disney goes to the well one too many times as ...</td>\n",
       "      <td>1331</td>\n",
       "      <td>230</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Just PPV'd this. I don't want to waste too muc...</td>\n",
       "      <td>985</td>\n",
       "      <td>184</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I am a guy, who loves guy movies... I was look...</td>\n",
       "      <td>1009</td>\n",
       "      <td>180</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positive</td>\n",
       "      <td>The opening flourishes left me purring with de...</td>\n",
       "      <td>3348</td>\n",
       "      <td>586</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Although in some aspects Seven Pounds is solid...</td>\n",
       "      <td>638</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Negative</td>\n",
       "      <td>I don't want to go off on a rant here, but.......</td>\n",
       "      <td>779</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text   len  nwords  \\\n",
       "0  Negative  Aldolpho (Steve Buscemi), an aspiring film mak...  1214     218   \n",
       "1  Negative  An unfunny, unworthy picture which is an undes...   121      22   \n",
       "2  Negative  A failure. The movie was just not good. It has...   750     145   \n",
       "3  Positive  I saw this movie Sunday afternoon. I absolutel...   698     136   \n",
       "4  Negative  Disney goes to the well one too many times as ...  1331     230   \n",
       "5  Negative  Just PPV'd this. I don't want to waste too muc...   985     184   \n",
       "6  Negative  I am a guy, who loves guy movies... I was look...  1009     180   \n",
       "7  Positive  The opening flourishes left me purring with de...  3348     586   \n",
       "8  Negative  Although in some aspects Seven Pounds is solid...   638     106   \n",
       "9  Negative  I don't want to go off on a rant here, but.......   779     131   \n",
       "\n",
       "   n_verbs1  n_verbs2  \n",
       "0        27        27  \n",
       "1         1         1  \n",
       "2         9         9  \n",
       "3        17        17  \n",
       "4        37        37  \n",
       "5        21        21  \n",
       "6        25        25  \n",
       "7        70        70  \n",
       "8         3         3  \n",
       "9         9         9  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining with feature unions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Suggestion**: try to vary the following options/parameters and analyze its impact:\n",
    "\n",
    "- Experiment a bit more with your preprocessing and see its impact\n",
    "- Try other feature extraction options such as the simple CountVectorizer\n",
    "- Use smaller slices of the dataset to see how the dataset size impacts both baseline and feature selected results\n",
    "- Experiment with other classifiers and the impact of the dimensionality reduction on these\n",
    "- Try to use the model to evaluate other text data, search for republican/democrat posts/news/blogs and see how well your model classifies each, for example political speeches.\n",
    "\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
